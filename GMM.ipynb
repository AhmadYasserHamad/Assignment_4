{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZmFwjCqIE/rOZWfcDnrVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmadYasserHamad/Assignment_4/blob/main/GMM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFUkUY2XRXH4",
        "outputId": "864f80a2-d487-4f2c-e3aa-509c0cfc408b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "# Quick look at the dataset\n",
        "print(df.head())\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IApdVQTuReZq",
        "outputId": "8a473709-482b-42ca-9d4a-c070c6dc3a98",
        "collapsed": true
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302         M        17.99         10.38          122.80     1001.0   \n",
            "1    842517         M        20.57         17.77          132.90     1326.0   \n",
            "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
            "3  84348301         M        11.42         20.38           77.58      386.1   \n",
            "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
            "0  ...          17.33           184.60      2019.0            0.1622   \n",
            "1  ...          23.41           158.80      1956.0            0.1238   \n",
            "2  ...          25.53           152.50      1709.0            0.1444   \n",
            "3  ...          26.50            98.87       567.7            0.2098   \n",
            "4  ...          16.67           152.20      1575.0            0.1374   \n",
            "\n",
            "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
            "0             0.6656           0.7119                0.2654          0.4601   \n",
            "1             0.1866           0.2416                0.1860          0.2750   \n",
            "2             0.4245           0.4504                0.2430          0.3613   \n",
            "3             0.8663           0.6869                0.2575          0.6638   \n",
            "4             0.2050           0.4000                0.1625          0.2364   \n",
            "\n",
            "   fractal_dimension_worst  Unnamed: 32  \n",
            "0                  0.11890          NaN  \n",
            "1                  0.08902          NaN  \n",
            "2                  0.08758          NaN  \n",
            "3                  0.17300          NaN  \n",
            "4                  0.07678          NaN  \n",
            "\n",
            "[5 rows x 33 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rfSzZAcjvjkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop un named column in data\n",
        "df = df.drop('Unnamed: 32', axis=1)\n",
        "print(\"\\nDropped 'Unnamed: 32' column (empty column)\")\n",
        "\n",
        "# Remove non-feature columns (id and diagnosis for unsupervised learning) and id have no meaning\n",
        "X = df.drop(['id', 'diagnosis'], axis=1, errors='ignore')\n",
        "\n",
        "print(f\"\\nRemaining columns: {X.columns.tolist()}\")\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "\n",
        "# Normalize the features using StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_normalized = scaler.fit_transform(X)\n",
        "\n",
        "# Convert back to DataFrame for easier viewing\n",
        "normalized_df = pd.DataFrame(X_normalized, columns=X.columns)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"NORMALIZATION COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nOriginal data statistics:\")\n",
        "print(X.describe())\n",
        "print(f\"\\nNormalized data statistics:\")\n",
        "print(normalized_df.describe())\n",
        "\n",
        "print(f\"\\nNormalized data shape: {X_normalized.shape}\")\n",
        "\n",
        "# Display first few rows of normalized data\n",
        "print(\"\\nFirst 5 rows of normalized data:\")\n",
        "print(normalized_df.head())"
      ],
      "metadata": {
        "id": "zmkUiJ0ZRqh5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "690a14b8-0897-4870-d5c1-de951dce935e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dropped 'Unnamed: 32' column (empty column)\n",
            "\n",
            "Remaining columns: ['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean', 'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean', 'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se', 'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se', 'fractal_dimension_se', 'radius_worst', 'texture_worst', 'perimeter_worst', 'area_worst', 'smoothness_worst', 'compactness_worst', 'concavity_worst', 'concave points_worst', 'symmetry_worst', 'fractal_dimension_worst']\n",
            "Features shape: (569, 30)\n",
            "\n",
            "==================================================\n",
            "NORMALIZATION COMPLETE\n",
            "==================================================\n",
            "\n",
            "Original data statistics:\n",
            "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
            "count   569.000000    569.000000      569.000000   569.000000   \n",
            "mean     14.127292     19.289649       91.969033   654.889104   \n",
            "std       3.524049      4.301036       24.298981   351.914129   \n",
            "min       6.981000      9.710000       43.790000   143.500000   \n",
            "25%      11.700000     16.170000       75.170000   420.300000   \n",
            "50%      13.370000     18.840000       86.240000   551.100000   \n",
            "75%      15.780000     21.800000      104.100000   782.700000   \n",
            "max      28.110000     39.280000      188.500000  2501.000000   \n",
            "\n",
            "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "count       569.000000        569.000000      569.000000           569.000000   \n",
            "mean          0.096360          0.104341        0.088799             0.048919   \n",
            "std           0.014064          0.052813        0.079720             0.038803   \n",
            "min           0.052630          0.019380        0.000000             0.000000   \n",
            "25%           0.086370          0.064920        0.029560             0.020310   \n",
            "50%           0.095870          0.092630        0.061540             0.033500   \n",
            "75%           0.105300          0.130400        0.130700             0.074000   \n",
            "max           0.163400          0.345400        0.426800             0.201200   \n",
            "\n",
            "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
            "count     569.000000              569.000000  ...    569.000000   \n",
            "mean        0.181162                0.062798  ...     16.269190   \n",
            "std         0.027414                0.007060  ...      4.833242   \n",
            "min         0.106000                0.049960  ...      7.930000   \n",
            "25%         0.161900                0.057700  ...     13.010000   \n",
            "50%         0.179200                0.061540  ...     14.970000   \n",
            "75%         0.195700                0.066120  ...     18.790000   \n",
            "max         0.304000                0.097440  ...     36.040000   \n",
            "\n",
            "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
            "count     569.000000       569.000000   569.000000        569.000000   \n",
            "mean       25.677223       107.261213   880.583128          0.132369   \n",
            "std         6.146258        33.602542   569.356993          0.022832   \n",
            "min        12.020000        50.410000   185.200000          0.071170   \n",
            "25%        21.080000        84.110000   515.300000          0.116600   \n",
            "50%        25.410000        97.660000   686.500000          0.131300   \n",
            "75%        29.720000       125.400000  1084.000000          0.146000   \n",
            "max        49.540000       251.200000  4254.000000          0.222600   \n",
            "\n",
            "       compactness_worst  concavity_worst  concave points_worst  \\\n",
            "count         569.000000       569.000000            569.000000   \n",
            "mean            0.254265         0.272188              0.114606   \n",
            "std             0.157336         0.208624              0.065732   \n",
            "min             0.027290         0.000000              0.000000   \n",
            "25%             0.147200         0.114500              0.064930   \n",
            "50%             0.211900         0.226700              0.099930   \n",
            "75%             0.339100         0.382900              0.161400   \n",
            "max             1.058000         1.252000              0.291000   \n",
            "\n",
            "       symmetry_worst  fractal_dimension_worst  \n",
            "count      569.000000               569.000000  \n",
            "mean         0.290076                 0.083946  \n",
            "std          0.061867                 0.018061  \n",
            "min          0.156500                 0.055040  \n",
            "25%          0.250400                 0.071460  \n",
            "50%          0.282200                 0.080040  \n",
            "75%          0.317900                 0.092080  \n",
            "max          0.663800                 0.207500  \n",
            "\n",
            "[8 rows x 30 columns]\n",
            "\n",
            "Normalized data statistics:\n",
            "        radius_mean  texture_mean  perimeter_mean     area_mean  \\\n",
            "count  5.690000e+02  5.690000e+02    5.690000e+02  5.690000e+02   \n",
            "mean  -1.373633e-16  6.868164e-17   -1.248757e-16 -2.185325e-16   \n",
            "std    1.000880e+00  1.000880e+00    1.000880e+00  1.000880e+00   \n",
            "min   -2.029648e+00 -2.229249e+00   -1.984504e+00 -1.454443e+00   \n",
            "25%   -6.893853e-01 -7.259631e-01   -6.919555e-01 -6.671955e-01   \n",
            "50%   -2.150816e-01 -1.046362e-01   -2.359800e-01 -2.951869e-01   \n",
            "75%    4.693926e-01  5.841756e-01    4.996769e-01  3.635073e-01   \n",
            "max    3.971288e+00  4.651889e+00    3.976130e+00  5.250529e+00   \n",
            "\n",
            "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
            "count     5.690000e+02      5.690000e+02    5.690000e+02         5.690000e+02   \n",
            "mean     -8.366672e-16      1.873136e-16    4.995028e-17        -4.995028e-17   \n",
            "std       1.000880e+00      1.000880e+00    1.000880e+00         1.000880e+00   \n",
            "min      -3.112085e+00     -1.610136e+00   -1.114873e+00        -1.261820e+00   \n",
            "25%      -7.109628e-01     -7.470860e-01   -7.437479e-01        -7.379438e-01   \n",
            "50%      -3.489108e-02     -2.219405e-01   -3.422399e-01        -3.977212e-01   \n",
            "75%       6.361990e-01      4.938569e-01    5.260619e-01         6.469351e-01   \n",
            "max       4.770911e+00      4.568425e+00    4.243589e+00         3.927930e+00   \n",
            "\n",
            "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
            "count   5.690000e+02            5.690000e+02  ...  5.690000e+02   \n",
            "mean    1.748260e-16            4.745277e-16  ... -8.241796e-16   \n",
            "std     1.000880e+00            1.000880e+00  ...  1.000880e+00   \n",
            "min    -2.744117e+00           -1.819865e+00  ... -1.726901e+00   \n",
            "25%    -7.032397e-01           -7.226392e-01  ... -6.749213e-01   \n",
            "50%    -7.162650e-02           -1.782793e-01  ... -2.690395e-01   \n",
            "75%     5.307792e-01            4.709834e-01  ...  5.220158e-01   \n",
            "max     4.484751e+00            4.910919e+00  ...  4.094189e+00   \n",
            "\n",
            "       texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
            "count   5.690000e+02     5.690000e+02  569.000000      5.690000e+02   \n",
            "mean    1.248757e-17    -3.746271e-16    0.000000     -2.372638e-16   \n",
            "std     1.000880e+00     1.000880e+00    1.000880      1.000880e+00   \n",
            "min    -2.223994e+00    -1.693361e+00   -1.222423     -2.682695e+00   \n",
            "25%    -7.486293e-01    -6.895783e-01   -0.642136     -6.912304e-01   \n",
            "50%    -4.351564e-02    -2.859802e-01   -0.341181     -4.684277e-02   \n",
            "75%     6.583411e-01     5.402790e-01    0.357589      5.975448e-01   \n",
            "max     3.885905e+00     4.287337e+00    5.930172      3.955374e+00   \n",
            "\n",
            "       compactness_worst  concavity_worst  concave points_worst  \\\n",
            "count       5.690000e+02     5.690000e+02          5.690000e+02   \n",
            "mean       -3.371644e-16     7.492542e-17          2.247763e-16   \n",
            "std         1.000880e+00     1.000880e+00          1.000880e+00   \n",
            "min        -1.443878e+00    -1.305831e+00         -1.745063e+00   \n",
            "25%        -6.810833e-01    -7.565142e-01         -7.563999e-01   \n",
            "50%        -2.695009e-01    -2.182321e-01         -2.234689e-01   \n",
            "75%         5.396688e-01     5.311411e-01          7.125100e-01   \n",
            "max         5.112877e+00     4.700669e+00          2.685877e+00   \n",
            "\n",
            "       symmetry_worst  fractal_dimension_worst  \n",
            "count    5.690000e+02             5.690000e+02  \n",
            "mean     2.622390e-16            -5.744282e-16  \n",
            "std      1.000880e+00             1.000880e+00  \n",
            "min     -2.160960e+00            -1.601839e+00  \n",
            "25%     -6.418637e-01            -6.919118e-01  \n",
            "50%     -1.274095e-01            -2.164441e-01  \n",
            "75%      4.501382e-01             4.507624e-01  \n",
            "max      6.046041e+00             6.846856e+00  \n",
            "\n",
            "[8 rows x 30 columns]\n",
            "\n",
            "Normalized data shape: (569, 30)\n",
            "\n",
            "First 5 rows of normalized data:\n",
            "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
            "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
            "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
            "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
            "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
            "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
            "\n",
            "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
            "0          3.283515        2.652874             2.532475       2.217515   \n",
            "1         -0.487072       -0.023846             0.548144       0.001392   \n",
            "2          1.052926        1.363478             2.037231       0.939685   \n",
            "3          3.402909        1.915897             1.451707       2.867383   \n",
            "4          0.539340        1.371011             1.428493      -0.009560   \n",
            "\n",
            "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
            "0                2.255747  ...      1.886690      -1.359293         2.303601   \n",
            "1               -0.868652  ...      1.805927      -0.369203         1.535126   \n",
            "2               -0.398008  ...      1.511870      -0.023974         1.347475   \n",
            "3                4.910919  ...     -0.281464       0.133984        -0.249939   \n",
            "4               -0.562450  ...      1.298575      -1.466770         1.338539   \n",
            "\n",
            "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
            "0    2.001237          1.307686           2.616665         2.109526   \n",
            "1    1.890489         -0.375612          -0.430444        -0.146749   \n",
            "2    1.456285          0.527407           1.082932         0.854974   \n",
            "3   -0.550021          3.394275           3.893397         1.989588   \n",
            "4    1.220724          0.220556          -0.313395         0.613179   \n",
            "\n",
            "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
            "0              2.296076        2.750622                 1.937015  \n",
            "1              1.087084       -0.243890                 0.281190  \n",
            "2              1.955000        1.152255                 0.201391  \n",
            "3              2.175786        6.046041                 4.935010  \n",
            "4              0.729259       -0.868353                -0.397100  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "class of gmm"
      ],
      "metadata": {
        "id": "eMb5-HGjvlWn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Literal\n",
        "\n",
        "class GaussianMixtureModel:\n",
        "    \"\"\"\n",
        "    Gaussian Mixture Model implementation using only NumPy\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_components: int = 2,\n",
        "        covariance_type: Literal['full', 'diagonal', 'spherical', 'tied'] = 'full',\n",
        "        init_method: Literal['kmeans++', 'random'] = 'kmeans++',\n",
        "        tol: float = 1e-4,\n",
        "        max_iter: int = 100,\n",
        "        random_state: int = None\n",
        "    ):\n",
        "        self.n_components = n_components\n",
        "        self.covariance_type = covariance_type\n",
        "        self.init_method = init_method\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Parameters to be learned\n",
        "        self.means_ = None          # Shape: (n_components, n_features)\n",
        "        self.covariances_ = None    # Shape depends on covariance_type\n",
        "        self.weights_ = None        # Shape: (n_components,)\n",
        "\n",
        "        # Training info\n",
        "        self.converged_ = False\n",
        "        self.n_iter_ = 0\n",
        "        self.log_likelihood_history_ = []\n",
        "\n",
        "        # Set random seed if provided\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "\n",
        "    def _kmeans_plus_plus(self, X):\n",
        "        \"\"\"\n",
        "        Initialize centers using k-means++ algorithm\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "        centers = np.zeros((self.n_components, n_features))\n",
        "\n",
        "        # Step 1: Choose first center randomly from data points\n",
        "        first_idx = np.random.randint(0, n_samples)\n",
        "        centers[0] = X[first_idx]\n",
        "\n",
        "        # Step 2: Choose remaining centers with probability proportional to distance squared\n",
        "        for i in range(1, self.n_components):\n",
        "            # Compute squared distances from each point to nearest existing center\n",
        "            distances = np.zeros(n_samples)\n",
        "\n",
        "            for j in range(n_samples):\n",
        "                # Distance to nearest center\n",
        "                min_dist = float('inf')\n",
        "                for k in range(i):\n",
        "                    dist = np.sum((X[j] - centers[k]) ** 2)\n",
        "                    min_dist = min(min_dist, dist)\n",
        "                distances[j] = min_dist\n",
        "\n",
        "            # Choose next center with probability proportional to distance squared\n",
        "            probabilities = distances / distances.sum()\n",
        "            next_idx = np.random.choice(n_samples, p=probabilities)\n",
        "            centers[i] = X[next_idx]\n",
        "\n",
        "        return centers\n",
        "\n",
        "    def _initialize_parameters(self, X):\n",
        "        \"\"\"\n",
        "        Initialize means, covariances, and weights for GMM\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Initialize means using k-means++\n",
        "        if self.init_method == 'kmeans++':\n",
        "            self.means_ = self._kmeans_plus_plus(X)\n",
        "        else:\n",
        "            # Random initialization (select random points from data)\n",
        "            indices = np.random.choice(n_samples, self.n_components, replace=False)\n",
        "            self.means_ = X[indices]\n",
        "\n",
        "        # Initialize covariances based on covariance_type\n",
        "        if self.covariance_type == 'full':\n",
        "            # Full covariance matrix for each component\n",
        "            # Shape: (n_components, n_features, n_features)\n",
        "            self.covariances_ = np.array([np.cov(X.T) for _ in range(self.n_components)])\n",
        "\n",
        "        elif self.covariance_type == 'diagonal':\n",
        "            # Diagonal covariance (only variances, no covariances)\n",
        "            # Shape: (n_components, n_features)\n",
        "            self.covariances_ = np.array([np.var(X, axis=0) for _ in range(self.n_components)])\n",
        "\n",
        "        elif self.covariance_type == 'spherical':\n",
        "            # Spherical covariance (single variance for all dimensions)\n",
        "            # Shape: (n_components,)\n",
        "            self.covariances_ = np.array([np.mean(np.var(X, axis=0)) for _ in range(self.n_components)])\n",
        "\n",
        "        elif self.covariance_type == 'tied':\n",
        "            # Tied covariance (single shared covariance matrix for all components)\n",
        "            # Shape: (n_features, n_features)\n",
        "            self.covariances_ = np.cov(X.T)\n",
        "\n",
        "        # Initialize weights (mixing coefficients) - uniform distribution\n",
        "        self.weights_ = np.ones(self.n_components) / self.n_components\n",
        "\n",
        "        print(f\"Initialized parameters:\")\n",
        "        print(f\"  Means shape: {self.means_.shape}\")\n",
        "        print(f\"  Covariances shape: {self.covariances_.shape}\")\n",
        "        print(f\"  Weights shape: {self.weights_.shape}\")\n",
        "\n",
        "    def _compute_gaussian_pdf(self, X, mean, covariance):\n",
        "        \"\"\"\n",
        "        Compute the probability density function of multivariate Gaussian distribution (for single component)\n",
        "        Returns:\n",
        "        --------\n",
        "        pdf : np.ndarray, shape (n_samples,)\n",
        "            Probability density for each data point\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Center the data\n",
        "        X_centered = X - mean  # Shape: (n_samples, n_features)\n",
        "\n",
        "        if self.covariance_type == 'full':\n",
        "            # Full covariance matrix: shape (n_features, n_features)\n",
        "            # Add small regularization to avoid singular matrix\n",
        "            cov_reg = covariance + 1e-6 * np.eye(n_features)\n",
        "\n",
        "            # Compute determinant and inverse\n",
        "            cov_det = np.linalg.det(cov_reg)\n",
        "            cov_inv = np.linalg.inv(cov_reg)\n",
        "\n",
        "            # Mahalanobis distance: (x - μ)^T Σ^(-1) (x - μ)\n",
        "            mahal_dist = np.sum(X_centered @ cov_inv * X_centered, axis=1)\n",
        "\n",
        "            # Normalization constant\n",
        "            norm_const = 1.0 / np.sqrt((2 * np.pi) ** n_features * cov_det)\n",
        "\n",
        "        elif self.covariance_type == 'diagonal':\n",
        "            # Diagonal covariance: shape (n_features,)\n",
        "            # Add regularization\n",
        "            cov_reg = covariance + 1e-6\n",
        "\n",
        "            # Compute determinant (product of diagonal elements)\n",
        "            cov_det = np.prod(cov_reg)\n",
        "\n",
        "            # Mahalanobis distance with diagonal covariance\n",
        "            mahal_dist = np.sum(X_centered ** 2 / cov_reg, axis=1)\n",
        "\n",
        "            # Normalization constant\n",
        "            norm_const = 1.0 / np.sqrt((2 * np.pi) ** n_features * cov_det)\n",
        "\n",
        "        elif self.covariance_type == 'spherical':\n",
        "            # Spherical covariance: scalar\n",
        "            # Add regularization\n",
        "            cov_reg = covariance + 1e-6\n",
        "\n",
        "            # Compute determinant (variance to the power of n_features)\n",
        "            cov_det = cov_reg ** n_features\n",
        "\n",
        "            # Mahalanobis distance with spherical covariance\n",
        "            mahal_dist = np.sum(X_centered ** 2, axis=1) / cov_reg\n",
        "\n",
        "            # Normalization constant\n",
        "            norm_const = 1.0 / np.sqrt((2 * np.pi) ** n_features * cov_det)\n",
        "\n",
        "        elif self.covariance_type == 'tied':\n",
        "            # Tied covariance: shape (n_features, n_features)\n",
        "            # Same as full, but this matrix is shared across all components\n",
        "            cov_reg = covariance + 1e-6 * np.eye(n_features)\n",
        "\n",
        "            cov_det = np.linalg.det(cov_reg)\n",
        "            cov_inv = np.linalg.inv(cov_reg)\n",
        "\n",
        "            mahal_dist = np.sum(X_centered @ cov_inv * X_centered, axis=1)\n",
        "            norm_const = 1.0 / np.sqrt((2 * np.pi) ** n_features * cov_det)\n",
        "\n",
        "        # Compute PDF using the formula: N(x|μ,Σ) = (1/√((2π)^k|Σ|)) * exp(-0.5 * mahal_dist)\n",
        "        pdf = norm_const * np.exp(-0.5 * mahal_dist)\n",
        "\n",
        "        return pdf\n",
        "\n",
        "    def _e_step(self, X):\n",
        "        \"\"\"\n",
        "        E-step: Compute responsibilities (posterior probabilities)\n",
        "        For each data point x_i and component k, compute:\n",
        "        γ(z_ik) = π_k * N(x_i | μ_k, Σ_k) / Σ_j[π_j * N(x_i | μ_j, Σ_j)]\n",
        "        Uses log-space computation for numerical stability.\n",
        "        responsibilities : np.ndarray, shape (n_samples, n_components)\n",
        "            Posterior probabilities that each sample belongs to each component\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        # Compute log weighted likelihoods for numerical stability\n",
        "        # log_weighted_likelihoods[i, k] = log(π_k) + log(N(x_i | μ_k, Σ_k))\n",
        "        log_weighted_likelihoods = np.zeros((n_samples, self.n_components))\n",
        "\n",
        "        for k in range(self.n_components):\n",
        "            # Get covariance for component k\n",
        "            if self.covariance_type == 'tied':\n",
        "                # All components share the same covariance\n",
        "                cov = self.covariances_\n",
        "            elif self.covariance_type == 'full' or self.covariance_type == 'diagonal':\n",
        "                cov = self.covariances_[k]\n",
        "            elif self.covariance_type == 'spherical':\n",
        "                cov = self.covariances_[k]\n",
        "\n",
        "            # Compute PDF for component k\n",
        "            pdf = self._compute_gaussian_pdf(X, self.means_[k], cov)\n",
        "\n",
        "            # Compute log weighted likelihood: log(π_k) + log(N(x_i | μ_k, Σ_k))\n",
        "            # Add small epsilon to avoid log(0)\n",
        "            log_weighted_likelihoods[:, k] = np.log(self.weights_[k] + 1e-10) + np.log(pdf + 1e-10)\n",
        "\n",
        "        # Use log-sum-exp trick for numerical stability\n",
        "        # log(sum(exp(x_i))) = max(x) + log(sum(exp(x_i - max(x))))\n",
        "        max_log = np.max(log_weighted_likelihoods, axis=1, keepdims=True)\n",
        "        log_sum_exp = max_log + np.log(np.sum(np.exp(log_weighted_likelihoods - max_log), axis=1, keepdims=True))\n",
        "\n",
        "        # Compute log responsibilities\n",
        "        log_responsibilities = log_weighted_likelihoods - log_sum_exp\n",
        "\n",
        "        # Convert back from log space\n",
        "        responsibilities = np.exp(log_responsibilities)\n",
        "\n",
        "        return responsibilities\n",
        "\n",
        "    def _m_step(self, X, responsibilities):\n",
        "        \"\"\"\n",
        "        M-step: Update parameters based on responsibilitie\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        # Compute effective number of points assigned to each component\n",
        "        # N_k = Σ_i γ(z_ik)\n",
        "        N_k = responsibilities.sum(axis=0)  # Shape: (n_components,)\n",
        "\n",
        "        # Update weights (mixing coefficients)\n",
        "        # π_k = N_k / N\n",
        "        self.weights_ = N_k / n_samples\n",
        "\n",
        "        # Update means\n",
        "        # μ_k = (1/N_k) * Σ_i γ(z_ik) * x_i\n",
        "        for k in range(self.n_components):\n",
        "            # Weighted sum of data points\n",
        "            weighted_sum = np.sum(responsibilities[:, k].reshape(-1, 1) * X, axis=0)\n",
        "            self.means_[k] = weighted_sum / N_k[k]\n",
        "\n",
        "        # Update covariances based on covariance type\n",
        "        if self.covariance_type == 'full':\n",
        "            # Full covariance matrix for each component\n",
        "            # Σ_k = (1/N_k) * Σ_i γ(z_ik) * (x_i - μ_k)(x_i - μ_k)^T\n",
        "            for k in range(self.n_components):\n",
        "                # Center the data\n",
        "                X_centered = X - self.means_[k]  # Shape: (n_samples, n_features)\n",
        "\n",
        "                # Weight each centered point by its responsibility\n",
        "                weighted_X_centered = responsibilities[:, k].reshape(-1, 1) * X_centered\n",
        "\n",
        "                # Compute covariance: Σ_k = (1/N_k) * X_centered^T * weighted_X_centered\n",
        "                self.covariances_[k] = (X_centered.T @ weighted_X_centered) / N_k[k]\n",
        "\n",
        "                # Add regularization to ensure positive definite matrix\n",
        "                self.covariances_[k] += 1e-6 * np.eye(n_features)\n",
        "\n",
        "        elif self.covariance_type == 'diagonal':\n",
        "            # Diagonal covariance (only variances)\n",
        "            # Σ_k = (1/N_k) * Σ_i γ(z_ik) * (x_i - μ_k)^2\n",
        "            for k in range(self.n_components):\n",
        "                X_centered = X - self.means_[k]\n",
        "                weighted_sq_diff = responsibilities[:, k].reshape(-1, 1) * (X_centered ** 2)\n",
        "                self.covariances_[k] = np.sum(weighted_sq_diff, axis=0) / N_k[k]\n",
        "\n",
        "                # Add regularization\n",
        "                self.covariances_[k] += 1e-6\n",
        "\n",
        "        elif self.covariance_type == 'spherical':\n",
        "            # Spherical covariance (single variance value)\n",
        "            # Σ_k = (1/(N_k * d)) * Σ_i γ(z_ik) * ||x_i - μ_k||^2\n",
        "            for k in range(self.n_components):\n",
        "                X_centered = X - self.means_[k]\n",
        "                weighted_sq_dist = responsibilities[:, k] * np.sum(X_centered ** 2, axis=1)\n",
        "                self.covariances_[k] = np.sum(weighted_sq_dist) / (N_k[k] * n_features)\n",
        "\n",
        "                # Add regularization\n",
        "                self.covariances_[k] += 1e-6\n",
        "\n",
        "        elif self.covariance_type == 'tied':\n",
        "            # Tied covariance (single shared covariance matrix for all components)\n",
        "            # Σ = (1/N) * Σ_k Σ_i γ(z_ik) * (x_i - μ_k)(x_i - μ_k)^T\n",
        "            self.covariances_ = np.zeros((n_features, n_features))\n",
        "\n",
        "            for k in range(self.n_components):\n",
        "                X_centered = X - self.means_[k]\n",
        "                weighted_X_centered = responsibilities[:, k].reshape(-1, 1) * X_centered\n",
        "                self.covariances_ += X_centered.T @ weighted_X_centered\n",
        "\n",
        "            self.covariances_ /= n_samples\n",
        "\n",
        "            # Add regularization\n",
        "            self.covariances_ += 1e-6 * np.eye(n_features)\n",
        "\n",
        "    def _compute_log_likelihood(self, X):\n",
        "        \"\"\"\n",
        "        Compute the log-likelihood of the data given current parameters\n",
        "        log L = Σ_i log(Σ_k π_k * N(x_i | μ_k, Σ_k))\n",
        "        Returns:\n",
        "        log_likelihood : float\n",
        "            Log-likelihood of the data\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        log_likelihood = 0.0\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            # Compute weighted likelihood for sample i across all components\n",
        "            sample_likelihood = 0.0\n",
        "\n",
        "            for k in range(self.n_components):\n",
        "                # Get covariance for component k\n",
        "                if self.covariance_type == 'tied':\n",
        "                    cov = self.covariances_\n",
        "                else:\n",
        "                    cov = self.covariances_[k]\n",
        "\n",
        "                # Compute PDF\n",
        "                pdf = self._compute_gaussian_pdf(X[i:i+1], self.means_[k], cov)\n",
        "\n",
        "                # Add weighted likelihood\n",
        "                sample_likelihood += self.weights_[k] * pdf[0]\n",
        "\n",
        "            # Add log of likelihood (with small epsilon to avoid log(0))\n",
        "            log_likelihood += np.log(sample_likelihood + 1e-10)\n",
        "\n",
        "        return log_likelihood\n",
        "\n",
        "    def fit(self, X, verbose=True):\n",
        "        \"\"\"\n",
        "        Fit the Gaussian Mixture Model using the EM algorithm\n",
        "        Returns\n",
        "        self : GaussianMixtureModel\n",
        "            Fitted model\n",
        "        \"\"\"\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if verbose:\n",
        "            print(\"=\"*70)\n",
        "            print(f\"FITTING GAUSSIAN MIXTURE MODEL\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Data shape: {X.shape}\")\n",
        "            print(f\"Number of components: {self.n_components}\")\n",
        "            print(f\"Covariance type: {self.covariance_type}\")\n",
        "            print(f\"Initialization method: {self.init_method}\")\n",
        "            print(f\"Max iterations: {self.max_iter}\")\n",
        "            print(f\"Tolerance: {self.tol}\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        # Initialize parameters\n",
        "        self._initialize_parameters(X)\n",
        "\n",
        "        # Compute initial log-likelihood\n",
        "        prev_log_likelihood = self._compute_log_likelihood(X)\n",
        "        self.log_likelihood_history_.append(prev_log_likelihood)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"\\nInitial log-likelihood: {prev_log_likelihood:.4f}\")\n",
        "            print(\"\\nStarting EM iterations...\")\n",
        "            print(\"-\"*70)\n",
        "\n",
        "        # EM algorithm loop\n",
        "        for iteration in range(self.max_iter):\n",
        "            # E-step: Compute responsibilities\n",
        "            responsibilities = self._e_step(X)\n",
        "\n",
        "            # M-step: Update parameters\n",
        "            self._m_step(X, responsibilities)\n",
        "\n",
        "            # Compute log-likelihood\n",
        "            current_log_likelihood = self._compute_log_likelihood(X)\n",
        "            self.log_likelihood_history_.append(current_log_likelihood)\n",
        "\n",
        "            # Check convergence\n",
        "            log_likelihood_change = current_log_likelihood - prev_log_likelihood\n",
        "\n",
        "            if verbose and (iteration + 1) % 10 == 0:\n",
        "                print(f\"Iteration {iteration + 1:3d}: Log-likelihood = {current_log_likelihood:.4f}, \"\n",
        "                      f\"Change = {log_likelihood_change:.6f}\")\n",
        "\n",
        "            # Check for convergence\n",
        "            if abs(log_likelihood_change) < self.tol:\n",
        "                self.converged_ = True\n",
        "                self.n_iter_ = iteration + 1\n",
        "                if verbose:\n",
        "                    print(\"-\"*70)\n",
        "                    print(f\"✓ Converged at iteration {iteration + 1}\")\n",
        "                    print(f\"  Final log-likelihood: {current_log_likelihood:.4f}\")\n",
        "                    print(f\"  Log-likelihood change: {log_likelihood_change:.6f}\")\n",
        "                break\n",
        "\n",
        "            prev_log_likelihood = current_log_likelihood\n",
        "            self.n_iter_ = iteration + 1\n",
        "\n",
        "        # If max iterations reached without convergence\n",
        "        if not self.converged_:\n",
        "            if verbose:\n",
        "                print(\"-\"*70)\n",
        "                print(f\"✗ Did not converge after {self.max_iter} iterations\")\n",
        "                print(f\"  Final log-likelihood: {current_log_likelihood:.4f}\")\n",
        "                print(f\"  Final change: {log_likelihood_change:.6f}\")\n",
        "\n",
        "        if verbose:\n",
        "            print(\"=\"*70)\n",
        "            print(\"TRAINING COMPLETE\")\n",
        "            print(\"=\"*70)\n",
        "            print(f\"Converged: {self.converged_}\")\n",
        "            print(f\"Iterations: {self.n_iter_}\")\n",
        "            print(f\"Final weights: {self.weights_}\")\n",
        "            print(\"=\"*70)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the component labels for data samples (hard assignment)\n",
        "        \"\"\"\n",
        "        responsibilities = self._e_step(X)\n",
        "        return np.argmax(responsibilities, axis=1)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Predict posterior probabilities for data samples (soft assignment)\n",
        "        \"\"\"\n",
        "        return self._e_step(X)\n",
        "\n",
        "    def score(self, X):\n",
        "        \"\"\"\n",
        "        Compute the log-likelihood of the data\n",
        "        \"\"\"\n",
        "        return self._compute_log_likelihood(X)"
      ],
      "metadata": {
        "id": "i08h-Qdevm1Y"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the GMM initialization with your normalized data\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TESTING GMM INITIALIZATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test 1: Full covariance with k-means++\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 1: Full Covariance + K-means++\")\n",
        "print(\"=\"*70)\n",
        "gmm_full = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='full',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "gmm_full._initialize_parameters(X_normalized)\n",
        "print(f\"\\nMeans:\\n{gmm_full.means_}\")\n",
        "print(f\"\\nWeights: {gmm_full.weights_}\")\n",
        "print(f\"\\nCovariances shape: {gmm_full.covariances_.shape}\")\n",
        "print(f\"First covariance matrix (first 5x5):\\n{gmm_full.covariances_[0][:5, :5]}\")\n",
        "\n",
        "# Test 2: Diagonal covariance with k-means++\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 2: Diagonal Covariance + K-means++\")\n",
        "print(\"=\"*70)\n",
        "gmm_diag = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='diagonal',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "gmm_diag._initialize_parameters(X_normalized)\n",
        "print(f\"\\nMeans:\\n{gmm_diag.means_}\")\n",
        "print(f\"\\nWeights: {gmm_diag.weights_}\")\n",
        "print(f\"\\nCovariances shape: {gmm_diag.covariances_.shape}\")\n",
        "print(f\"First component covariances (first 10 features):\\n{gmm_diag.covariances_[0][:10]}\")\n",
        "\n",
        "# Test 3: Spherical covariance with k-means++\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 3: Spherical Covariance + K-means++\")\n",
        "print(\"=\"*70)\n",
        "gmm_spher = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='spherical',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "gmm_spher._initialize_parameters(X_normalized)\n",
        "print(f\"\\nMeans:\\n{gmm_spher.means_}\")\n",
        "print(f\"\\nWeights: {gmm_spher.weights_}\")\n",
        "print(f\"\\nCovariances shape: {gmm_spher.covariances_.shape}\")\n",
        "print(f\"Covariances (scalar for each component): {gmm_spher.covariances_}\")\n",
        "\n",
        "# Test 4: Tied covariance with k-means++\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 4: Tied Covariance + K-means++\")\n",
        "print(\"=\"*70)\n",
        "gmm_tied = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='tied',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "gmm_tied._initialize_parameters(X_normalized)\n",
        "print(f\"\\nMeans:\\n{gmm_tied.means_}\")\n",
        "print(f\"\\nWeights: {gmm_tied.weights_}\")\n",
        "print(f\"\\nCovariances shape: {gmm_tied.covariances_.shape}\")\n",
        "print(f\"Tied covariance matrix (first 5x5):\\n{gmm_tied.covariances_[:5, :5]}\")\n",
        "\n",
        "# Verify that means are different but initialized from data\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VERIFICATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Data shape: {X_normalized.shape}\")\n",
        "print(f\"Data min: {X_normalized.min():.3f}, max: {X_normalized.max():.3f}\")\n",
        "print(f\"\\nAll weights sum to 1.0: {np.allclose(gmm_full.weights_.sum(), 1.0)}\")\n",
        "print(f\"Means are from data range: {(gmm_full.means_.min() >= X_normalized.min() and gmm_full.means_.max() <= X_normalized.max())}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CCFkByRVyGDF",
        "outputId": "67878e88-c389-43e3-ed40-3908a09c37df"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TESTING GMM INITIALIZATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TEST 1: Full Covariance + K-means++\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2, 30, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Means:\n",
            "[[-0.5530585   0.28631105 -0.60751564 -0.55798194 -1.15503513 -1.21215527\n",
            "  -0.81568788 -0.8052661  -0.2651265  -0.85447642 -0.76793904  0.64254367\n",
            "  -0.83316584 -0.5644996  -0.65368614 -1.08314703 -0.70305211 -0.81090835\n",
            "  -0.73522485 -0.85594642 -0.60658404  1.16641373 -0.67557894 -0.58500369\n",
            "  -0.87972471 -1.05373391 -0.75651421 -0.61357437 -0.33448538 -0.84042616]\n",
            " [ 1.71905507  0.05825847  1.72302589  1.69255646  1.20552258  0.84445927\n",
            "   1.56310249  1.98564279 -0.31989066 -0.32145729  0.10079781 -0.39163235\n",
            "   0.07026503  0.26738504  0.68203468  0.09343955  0.78138781  1.18475716\n",
            "   0.48040333  0.07946914  1.19296315 -0.09888253  1.15386726  1.05196463\n",
            "   1.4961806   0.25404212  1.24069484  1.56367679  0.21232446 -0.17709882]]\n",
            "\n",
            "Weights: [0.5 0.5]\n",
            "\n",
            "Covariances shape: (2, 30, 30)\n",
            "First covariance matrix (first 5x5):\n",
            "[[ 1.00176056  0.32435193  0.99961207  0.98909547  0.17088151]\n",
            " [ 0.32435193  1.00176056  0.33011322  0.32165099 -0.02342969]\n",
            " [ 0.99961207  0.33011322  1.00176056  0.98824361  0.20764309]\n",
            " [ 0.98909547  0.32165099  0.98824361  1.00176056  0.17734005]\n",
            " [ 0.17088151 -0.02342969  0.20764309  0.17734005  1.00176056]]\n",
            "\n",
            "======================================================================\n",
            "TEST 2: Diagonal Covariance + K-means++\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Means:\n",
            "[[-0.5530585   0.28631105 -0.60751564 -0.55798194 -1.15503513 -1.21215527\n",
            "  -0.81568788 -0.8052661  -0.2651265  -0.85447642 -0.76793904  0.64254367\n",
            "  -0.83316584 -0.5644996  -0.65368614 -1.08314703 -0.70305211 -0.81090835\n",
            "  -0.73522485 -0.85594642 -0.60658404  1.16641373 -0.67557894 -0.58500369\n",
            "  -0.87972471 -1.05373391 -0.75651421 -0.61357437 -0.33448538 -0.84042616]\n",
            " [ 1.71905507  0.05825847  1.72302589  1.69255646  1.20552258  0.84445927\n",
            "   1.56310249  1.98564279 -0.31989066 -0.32145729  0.10079781 -0.39163235\n",
            "   0.07026503  0.26738504  0.68203468  0.09343955  0.78138781  1.18475716\n",
            "   0.48040333  0.07946914  1.19296315 -0.09888253  1.15386726  1.05196463\n",
            "   1.4961806   0.25404212  1.24069484  1.56367679  0.21232446 -0.17709882]]\n",
            "\n",
            "Weights: [0.5 0.5]\n",
            "\n",
            "Covariances shape: (2, 30)\n",
            "First component covariances (first 10 features):\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "\n",
            "======================================================================\n",
            "TEST 3: Spherical Covariance + K-means++\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2,)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Means:\n",
            "[[-0.5530585   0.28631105 -0.60751564 -0.55798194 -1.15503513 -1.21215527\n",
            "  -0.81568788 -0.8052661  -0.2651265  -0.85447642 -0.76793904  0.64254367\n",
            "  -0.83316584 -0.5644996  -0.65368614 -1.08314703 -0.70305211 -0.81090835\n",
            "  -0.73522485 -0.85594642 -0.60658404  1.16641373 -0.67557894 -0.58500369\n",
            "  -0.87972471 -1.05373391 -0.75651421 -0.61357437 -0.33448538 -0.84042616]\n",
            " [ 1.71905507  0.05825847  1.72302589  1.69255646  1.20552258  0.84445927\n",
            "   1.56310249  1.98564279 -0.31989066 -0.32145729  0.10079781 -0.39163235\n",
            "   0.07026503  0.26738504  0.68203468  0.09343955  0.78138781  1.18475716\n",
            "   0.48040333  0.07946914  1.19296315 -0.09888253  1.15386726  1.05196463\n",
            "   1.4961806   0.25404212  1.24069484  1.56367679  0.21232446 -0.17709882]]\n",
            "\n",
            "Weights: [0.5 0.5]\n",
            "\n",
            "Covariances shape: (2,)\n",
            "Covariances (scalar for each component): [1. 1.]\n",
            "\n",
            "======================================================================\n",
            "TEST 4: Tied Covariance + K-means++\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (30, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Means:\n",
            "[[-0.5530585   0.28631105 -0.60751564 -0.55798194 -1.15503513 -1.21215527\n",
            "  -0.81568788 -0.8052661  -0.2651265  -0.85447642 -0.76793904  0.64254367\n",
            "  -0.83316584 -0.5644996  -0.65368614 -1.08314703 -0.70305211 -0.81090835\n",
            "  -0.73522485 -0.85594642 -0.60658404  1.16641373 -0.67557894 -0.58500369\n",
            "  -0.87972471 -1.05373391 -0.75651421 -0.61357437 -0.33448538 -0.84042616]\n",
            " [ 1.71905507  0.05825847  1.72302589  1.69255646  1.20552258  0.84445927\n",
            "   1.56310249  1.98564279 -0.31989066 -0.32145729  0.10079781 -0.39163235\n",
            "   0.07026503  0.26738504  0.68203468  0.09343955  0.78138781  1.18475716\n",
            "   0.48040333  0.07946914  1.19296315 -0.09888253  1.15386726  1.05196463\n",
            "   1.4961806   0.25404212  1.24069484  1.56367679  0.21232446 -0.17709882]]\n",
            "\n",
            "Weights: [0.5 0.5]\n",
            "\n",
            "Covariances shape: (30, 30)\n",
            "Tied covariance matrix (first 5x5):\n",
            "[[ 1.00176056  0.32435193  0.99961207  0.98909547  0.17088151]\n",
            " [ 0.32435193  1.00176056  0.33011322  0.32165099 -0.02342969]\n",
            " [ 0.99961207  0.33011322  1.00176056  0.98824361  0.20764309]\n",
            " [ 0.98909547  0.32165099  0.98824361  1.00176056  0.17734005]\n",
            " [ 0.17088151 -0.02342969  0.20764309  0.17734005  1.00176056]]\n",
            "\n",
            "======================================================================\n",
            "VERIFICATION\n",
            "======================================================================\n",
            "Data shape: (569, 30)\n",
            "Data min: -3.112, max: 12.073\n",
            "\n",
            "All weights sum to 1.0: True\n",
            "Means are from data range: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING E-STEP (EXPECTATION) - FULL COVARIANCE ONLY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize GMM with full covariance\n",
        "gmm_test = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='full',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "gmm_test._initialize_parameters(X_normalized)\n",
        "\n",
        "# Compute responsibilities\n",
        "responsibilities = gmm_test._e_step(X_normalized)\n",
        "\n",
        "print(f\"\\nResponsibilities shape: {responsibilities.shape}\")\n",
        "print(f\"Expected shape: ({X_normalized.shape[0]}, {gmm_test.n_components})\")\n",
        "\n",
        "# Check first 10 samples\n",
        "print(f\"\\nFirst 10 samples responsibilities:\")\n",
        "print(responsibilities[:10])\n",
        "\n",
        "# Verify properties\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"VERIFICATION CHECKS:\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Check 1: Each row should sum to 1\n",
        "row_sums = responsibilities.sum(axis=1)\n",
        "print(f\"✓ All rows sum to 1.0: {np.allclose(row_sums, 1.0)}\")\n",
        "print(f\"  Min row sum: {row_sums.min():.10f}, Max row sum: {row_sums.max():.10f}\")\n",
        "\n",
        "# Check 2: Values should be between 0 and 1\n",
        "print(f\"✓ All values in [0, 1]: {(responsibilities >= 0).all() and (responsibilities <= 1).all()}\")\n",
        "print(f\"  Min value: {responsibilities.min():.10f}, Max value: {responsibilities.max():.10f}\")\n",
        "\n",
        "# Check 3: Distribution of responsibilities\n",
        "print(f\"\\n✓ Responsibility statistics:\")\n",
        "print(f\"  Component 0 - Mean: {responsibilities[:, 0].mean():.4f}, Std: {responsibilities[:, 0].std():.4f}\")\n",
        "print(f\"  Component 1 - Mean: {responsibilities[:, 1].mean():.4f}, Std: {responsibilities[:, 1].std():.4f}\")\n",
        "\n",
        "# Check 4: Hard assignments (which component has higher responsibility)\n",
        "hard_assignments = np.argmax(responsibilities, axis=1)\n",
        "unique, counts = np.unique(hard_assignments, return_counts=True)\n",
        "print(f\"\\n✓ Hard cluster assignments:\")\n",
        "for comp, count in zip(unique, counts):\n",
        "    print(f\"  Component {comp}: {count} samples ({count/len(hard_assignments)*100:.1f}%)\")\n",
        "\n",
        "# Check 5: Show some \"confident\" and \"uncertain\" assignments\n",
        "component_0_resp = responsibilities[:, 0]\n",
        "print(f\"\\n✓ Sample assignments:\")\n",
        "print(f\"  Most confident for Component 0 (resp ≈ 1.0):\")\n",
        "most_confident_0 = np.argsort(component_0_resp)[-5:]\n",
        "for idx in most_confident_0:\n",
        "    print(f\"    Sample {idx}: Component 0 = {responsibilities[idx, 0]:.6f}, Component 1 = {responsibilities[idx, 1]:.6f}\")\n",
        "\n",
        "print(f\"\\n  Most confident for Component 1 (resp ≈ 1.0):\")\n",
        "most_confident_1 = np.argsort(component_0_resp)[:5]\n",
        "for idx in most_confident_1:\n",
        "    print(f\"    Sample {idx}: Component 0 = {responsibilities[idx, 0]:.6f}, Component 1 = {responsibilities[idx, 1]:.6f}\")\n",
        "\n",
        "print(f\"\\n  Most uncertain (resp ≈ 0.5):\")\n",
        "uncertainty = np.abs(component_0_resp - 0.5)\n",
        "most_uncertain = np.argsort(uncertainty)[:5]\n",
        "for idx in most_uncertain:\n",
        "    print(f\"    Sample {idx}: Component 0 = {responsibilities[idx, 0]:.6f}, Component 1 = {responsibilities[idx, 1]:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6l-VjalA2Ozu",
        "outputId": "aa84d2db-43e2-4666-f74b-79bb8ac01324"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING E-STEP (EXPECTATION) - FULL COVARIANCE ONLY\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2, 30, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Responsibilities shape: (569, 2)\n",
            "Expected shape: (569, 2)\n",
            "\n",
            "First 10 samples responsibilities:\n",
            "[[5.00000000e-01 5.00000000e-01]\n",
            " [9.98555177e-01 1.44482280e-03]\n",
            " [2.36804025e-02 9.76319597e-01]\n",
            " [5.00000000e-01 5.00000000e-01]\n",
            " [2.97001103e-04 9.99702999e-01]\n",
            " [8.54587483e-01 1.45412517e-01]\n",
            " [9.78065441e-01 2.19345592e-02]\n",
            " [9.99991342e-01 8.65751892e-06]\n",
            " [9.99834722e-01 1.65277666e-04]\n",
            " [5.00000000e-01 5.00000000e-01]]\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "VERIFICATION CHECKS:\n",
            "----------------------------------------------------------------------\n",
            "✓ All rows sum to 1.0: True\n",
            "  Min row sum: 1.0000000000, Max row sum: 1.0000000000\n",
            "✓ All values in [0, 1]: True\n",
            "  Min value: 0.0000000001, Max value: 0.9999999999\n",
            "\n",
            "✓ Responsibility statistics:\n",
            "  Component 0 - Mean: 0.7750, Std: 0.3266\n",
            "  Component 1 - Mean: 0.2250, Std: 0.3266\n",
            "\n",
            "✓ Hard cluster assignments:\n",
            "  Component 0: 474 samples (83.3%)\n",
            "  Component 1: 95 samples (16.7%)\n",
            "\n",
            "✓ Sample assignments:\n",
            "  Most confident for Component 0 (resp ≈ 1.0):\n",
            "    Sample 298: Component 0 = 1.000000, Component 1 = 0.000000\n",
            "    Sample 470: Component 0 = 1.000000, Component 1 = 0.000000\n",
            "    Sample 40: Component 0 = 1.000000, Component 1 = 0.000000\n",
            "    Sample 410: Component 0 = 1.000000, Component 1 = 0.000000\n",
            "    Sample 102: Component 0 = 1.000000, Component 1 = 0.000000\n",
            "\n",
            "  Most confident for Component 1 (resp ≈ 1.0):\n",
            "    Sample 432: Component 0 = 0.000000, Component 1 = 1.000000\n",
            "    Sample 45: Component 0 = 0.000001, Component 1 = 0.999999\n",
            "    Sample 451: Component 0 = 0.000003, Component 1 = 0.999997\n",
            "    Sample 59: Component 0 = 0.000231, Component 1 = 0.999769\n",
            "    Sample 277: Component 0 = 0.000258, Component 1 = 0.999742\n",
            "\n",
            "  Most uncertain (resp ≈ 0.5):\n",
            "    Sample 3: Component 0 = 0.500000, Component 1 = 0.500000\n",
            "    Sample 38: Component 0 = 0.500000, Component 1 = 0.500000\n",
            "    Sample 12: Component 0 = 0.500000, Component 1 = 0.500000\n",
            "    Sample 9: Component 0 = 0.500000, Component 1 = 0.500000\n",
            "    Sample 68: Component 0 = 0.500000, Component 1 = 0.500000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING M-STEP (MAXIMIZATION) - FULL COVARIANCE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Initialize GMM with full covariance\n",
        "gmm_test = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='full',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 1: Initialize Parameters\")\n",
        "print(\"-\"*70)\n",
        "gmm_test._initialize_parameters(X_normalized)\n",
        "\n",
        "# Store initial parameters\n",
        "initial_means = gmm_test.means_.copy()\n",
        "initial_covariances = gmm_test.covariances_.copy()\n",
        "initial_weights = gmm_test.weights_.copy()\n",
        "\n",
        "print(f\"\\nInitial means (first component, first 5 features):\")\n",
        "print(initial_means[0, :5])\n",
        "print(f\"\\nInitial weights: {initial_weights}\")\n",
        "print(f\"\\nInitial covariance shape: {initial_covariances.shape}\")\n",
        "\n",
        "# Compute responsibilities (E-step)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 2: E-step - Compute Responsibilities\")\n",
        "print(\"-\"*70)\n",
        "responsibilities = gmm_test._e_step(X_normalized)\n",
        "print(f\"Responsibilities shape: {responsibilities.shape}\")\n",
        "print(f\"First 5 samples responsibilities:\")\n",
        "print(responsibilities[:5])\n",
        "\n",
        "# Update parameters (M-step)\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"STEP 3: M-step - Update Parameters\")\n",
        "print(\"-\"*70)\n",
        "gmm_test._m_step(X_normalized, responsibilities)\n",
        "\n",
        "# Store updated parameters\n",
        "updated_means = gmm_test.means_.copy()\n",
        "updated_covariances = gmm_test.covariances_.copy()\n",
        "updated_weights = gmm_test.weights_.copy()\n",
        "\n",
        "print(f\"\\nUpdated means (first component, first 5 features):\")\n",
        "print(updated_means[0, :5])\n",
        "print(f\"\\nUpdated weights: {updated_weights}\")\n",
        "print(f\"\\nUpdated covariance shape: {updated_covariances.shape}\")\n",
        "\n",
        "# Check that parameters changed\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"VERIFICATION: Parameters Changed?\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "means_changed = not np.allclose(initial_means, updated_means)\n",
        "weights_changed = not np.allclose(initial_weights, updated_weights)\n",
        "covariances_changed = not np.allclose(initial_covariances, updated_covariances)\n",
        "\n",
        "print(f\"✓ Means changed: {means_changed}\")\n",
        "if means_changed:\n",
        "    mean_diff = np.abs(updated_means - initial_means).max()\n",
        "    print(f\"  Max absolute change in means: {mean_diff:.6f}\")\n",
        "\n",
        "print(f\"\\n✓ Weights changed: {weights_changed}\")\n",
        "if weights_changed:\n",
        "    weight_diff = np.abs(updated_weights - initial_weights)\n",
        "    print(f\"  Weight changes: {weight_diff}\")\n",
        "    print(f\"  Initial weights: {initial_weights}\")\n",
        "    print(f\"  Updated weights: {updated_weights}\")\n",
        "\n",
        "print(f\"\\n✓ Covariances changed: {covariances_changed}\")\n",
        "if covariances_changed:\n",
        "    cov_diff = np.abs(updated_covariances - initial_covariances).max()\n",
        "    print(f\"  Max absolute change in covariances: {cov_diff:.6f}\")\n",
        "\n",
        "# Verify weights sum to 1\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"VERIFICATION: Weights Properties\")\n",
        "print(\"-\"*70)\n",
        "print(f\"✓ Weights sum to 1.0: {np.allclose(updated_weights.sum(), 1.0)}\")\n",
        "print(f\"  Actual sum: {updated_weights.sum():.10f}\")\n",
        "print(f\"✓ All weights > 0: {(updated_weights > 0).all()}\")\n",
        "print(f\"✓ All weights < 1: {(updated_weights < 1).all()}\")\n",
        "\n",
        "# Verify covariances are positive definite\n",
        "print(\"\\n\" + \"-\"*70)\n",
        "print(\"VERIFICATION: Covariance Properties\")\n",
        "print(\"-\"*70)\n",
        "for k in range(gmm_test.n_components):\n",
        "    eigenvalues = np.linalg.eigvals(updated_covariances[k])\n",
        "    is_positive_definite = (eigenvalues > 0).all()\n",
        "    print(f\"✓ Component {k} covariance is positive definite: {is_positive_definite}\")\n",
        "    print(f\"  Min eigenvalue: {eigenvalues.min():.6e}\")\n",
        "    print(f\"  Max eigenvalue: {eigenvalues.max():.6e}\")\n",
        "\n",
        "# Run multiple EM iterations to see convergence\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING MULTIPLE EM ITERATIONS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "gmm_iter = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='full',\n",
        "    init_method='kmeans++',\n",
        "    random_state=42\n",
        ")\n",
        "gmm_iter._initialize_parameters(X_normalized)\n",
        "\n",
        "print(\"\\nRunning 5 EM iterations...\")\n",
        "for iteration in range(5):\n",
        "    # E-step\n",
        "    resp = gmm_iter._e_step(X_normalized)\n",
        "\n",
        "    # M-step\n",
        "    gmm_iter._m_step(X_normalized, resp)\n",
        "\n",
        "    print(f\"\\nIteration {iteration + 1}:\")\n",
        "    print(f\"  Weights: {gmm_iter.weights_}\")\n",
        "    print(f\"  Mean[0] (first 3 features): {gmm_iter.means_[0, :3]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfTKoxp76w7X",
        "outputId": "bc82fa78-9e2f-42b6-ef5f-5198d2312e6d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING M-STEP (MAXIMIZATION) - FULL COVARIANCE\n",
            "======================================================================\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STEP 1: Initialize Parameters\n",
            "----------------------------------------------------------------------\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2, 30, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Initial means (first component, first 5 features):\n",
            "[-0.5530585   0.28631105 -0.60751564 -0.55798194 -1.15503513]\n",
            "\n",
            "Initial weights: [0.5 0.5]\n",
            "\n",
            "Initial covariance shape: (2, 30, 30)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STEP 2: E-step - Compute Responsibilities\n",
            "----------------------------------------------------------------------\n",
            "Responsibilities shape: (569, 2)\n",
            "First 5 samples responsibilities:\n",
            "[[5.00000000e-01 5.00000000e-01]\n",
            " [9.98555177e-01 1.44482280e-03]\n",
            " [2.36804025e-02 9.76319597e-01]\n",
            " [5.00000000e-01 5.00000000e-01]\n",
            " [2.97001103e-04 9.99702999e-01]]\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "STEP 3: M-step - Update Parameters\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Updated means (first component, first 5 features):\n",
            "[-0.14090857 -0.01981093 -0.1458565  -0.14556207 -0.11117618]\n",
            "\n",
            "Updated weights: [0.77502296 0.22497704]\n",
            "\n",
            "Updated covariance shape: (2, 30, 30)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "VERIFICATION: Parameters Changed?\n",
            "----------------------------------------------------------------------\n",
            "✓ Means changed: True\n",
            "  Max absolute change in means: 1.364148\n",
            "\n",
            "✓ Weights changed: True\n",
            "  Weight changes: [0.27502296 0.27502296]\n",
            "  Initial weights: [0.5 0.5]\n",
            "  Updated weights: [0.77502296 0.22497704]\n",
            "\n",
            "✓ Covariances changed: True\n",
            "  Max absolute change in covariances: 0.793654\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "VERIFICATION: Weights Properties\n",
            "----------------------------------------------------------------------\n",
            "✓ Weights sum to 1.0: True\n",
            "  Actual sum: 1.0000000000\n",
            "✓ All weights > 0: True\n",
            "✓ All weights < 1: True\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "VERIFICATION: Covariance Properties\n",
            "----------------------------------------------------------------------\n",
            "✓ Component 0 covariance is positive definite: True\n",
            "  Min eigenvalue: 1.006905e-04\n",
            "  Max eigenvalue: 1.075383e+01\n",
            "✓ Component 1 covariance is positive definite: True\n",
            "  Min eigenvalue: 2.226247e-04\n",
            "  Max eigenvalue: 1.693879e+01\n",
            "\n",
            "======================================================================\n",
            "TESTING MULTIPLE EM ITERATIONS\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2, 30, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Running 5 EM iterations...\n",
            "\n",
            "Iteration 1:\n",
            "  Weights: [0.77502296 0.22497704]\n",
            "  Mean[0] (first 3 features): [-0.14090857 -0.01981093 -0.1458565 ]\n",
            "\n",
            "Iteration 2:\n",
            "  Weights: [0.83687143 0.16312857]\n",
            "  Mean[0] (first 3 features): [-0.17058507 -0.07973056 -0.1763478 ]\n",
            "\n",
            "Iteration 3:\n",
            "  Weights: [0.83221754 0.16778246]\n",
            "  Mean[0] (first 3 features): [-0.19874015 -0.08906664 -0.20497992]\n",
            "\n",
            "Iteration 4:\n",
            "  Weights: [0.81606268 0.18393732]\n",
            "  Mean[0] (first 3 features): [-0.22436599 -0.09642131 -0.23175161]\n",
            "\n",
            "Iteration 5:\n",
            "  Weights: [0.79910723 0.20089277]\n",
            "  Mean[0] (first 3 features): [-0.25284984 -0.10724065 -0.26082184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "final test"
      ],
      "metadata": {
        "id": "vBbdAc1j-RqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TESTING COMPLETE GMM IMPLEMENTATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test 1: Fit the model with full covariance\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 1: Fit GMM with Full Covariance\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "gmm_full = GaussianMixtureModel(\n",
        "    n_components=2,\n",
        "    covariance_type='full',\n",
        "    init_method='kmeans++',\n",
        "    tol=1e-4,\n",
        "    max_iter=100,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "gmm_full.fit(X_normalized, verbose=True)\n",
        "\n",
        "# Test 2: Make predictions\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 2: Predictions\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Hard predictions\n",
        "labels = gmm_full.predict(X_normalized)\n",
        "print(f\"\\nHard predictions (labels) shape: {labels.shape}\")\n",
        "print(f\"Unique labels: {np.unique(labels)}\")\n",
        "print(f\"First 20 predictions: {labels[:20]}\")\n",
        "\n",
        "# Count samples per cluster\n",
        "unique_labels, counts = np.unique(labels, return_counts=True)\n",
        "print(f\"\\nCluster distribution:\")\n",
        "for label, count in zip(unique_labels, counts):\n",
        "    print(f\"  Cluster {label}: {count} samples ({count/len(labels)*100:.1f}%)\")\n",
        "\n",
        "# Soft predictions (probabilities)\n",
        "probabilities = gmm_full.predict_proba(X_normalized)\n",
        "print(f\"\\nSoft predictions (probabilities) shape: {probabilities.shape}\")\n",
        "print(f\"First 5 samples probabilities:\")\n",
        "print(probabilities[:5])\n",
        "\n",
        "# Test 3: Score (log-likelihood)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 3: Model Score\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "score = gmm_full.score(X_normalized)\n",
        "print(f\"Final log-likelihood: {score:.4f}\")\n",
        "print(f\"Log-likelihood history length: {len(gmm_full.log_likelihood_history_)}\")\n",
        "\n",
        "# Test 4: Visualize log-likelihood convergence\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 4: Convergence Visualization\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(gmm_full.log_likelihood_history_, marker='o', linestyle='-', linewidth=2)\n",
        "plt.xlabel('Iteration', fontsize=12)\n",
        "plt.ylabel('Log-Likelihood', fontsize=12)\n",
        "plt.title('GMM Convergence - Log-Likelihood over Iterations', fontsize=14)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"✓ Plotted log-likelihood convergence\")\n",
        "\n",
        "# Test 5: Model properties\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEST 5: Final Model Properties\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nConverged: {gmm_full.converged_}\")\n",
        "print(f\"Number of iterations: {gmm_full.n_iter_}\")\n",
        "print(f\"\\nFinal component weights: {gmm_full.weights_}\")\n",
        "print(f\"\\nMeans shape: {gmm_full.means_.shape}\")\n",
        "print(f\"Component 0 mean (first 5 features): {gmm_full.means_[0, :5]}\")\n",
        "print(f\"Component 1 mean (first 5 features): {gmm_full.means_[1, :5]}\")\n",
        "print(f\"\\nCovariances shape: {gmm_full.covariances_.shape}\")\n",
        "\n",
        "# Check covariance properties\n",
        "for k in range(gmm_full.n_components):\n",
        "    eigenvalues = np.linalg.eigvals(gmm_full.covariances_[k])\n",
        "    print(f\"\\nComponent {k} covariance:\")\n",
        "    print(f\"  Min eigenvalue: {eigenvalues.min():.6e}\")\n",
        "    print(f\"  Max eigenvalue: {eigenvalues.max():.6e}\")\n",
        "    print(f\"  Condition number: {eigenvalues.max() / eigenvalues.min():.2f}\")\n",
        "\n",
        "# Test 6: Compare with actual labels (if available in original data)\n",
        "if 'diagnosis' in df.columns:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"TEST 6: Comparison with True Labels\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Get true labels\n",
        "    true_labels = df['diagnosis'].map({'M': 1, 'B': 0}).values\n",
        "\n",
        "    # Compare with predictions\n",
        "    from sklearn.metrics import confusion_matrix, adjusted_rand_score\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(true_labels, labels)\n",
        "    print(f\"\\nConfusion Matrix:\")\n",
        "    print(cm)\n",
        "\n",
        "    # Compute Adjusted Rand Index\n",
        "    ari = adjusted_rand_score(true_labels, labels)\n",
        "    print(f\"\\nAdjusted Rand Index: {ari:.4f}\")\n",
        "\n",
        "    # Compute accuracy (may need to flip labels)\n",
        "    accuracy1 = np.mean(labels == true_labels)\n",
        "    accuracy2 = np.mean(labels == (1 - true_labels))\n",
        "    best_accuracy = max(accuracy1, accuracy2)\n",
        "    print(f\"Best matching accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ALL TESTS COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "teU534sD-Q7-",
        "outputId": "bd0aa9d9-f1f3-42b7-ba4b-0e023235f930"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TESTING COMPLETE GMM IMPLEMENTATION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TEST 1: Fit GMM with Full Covariance\n",
            "======================================================================\n",
            "======================================================================\n",
            "FITTING GAUSSIAN MIXTURE MODEL\n",
            "======================================================================\n",
            "Data shape: (569, 30)\n",
            "Number of components: 2\n",
            "Covariance type: full\n",
            "Initialization method: kmeans++\n",
            "Max iterations: 100\n",
            "Tolerance: 0.0001\n",
            "======================================================================\n",
            "Initialized parameters:\n",
            "  Means shape: (2, 30)\n",
            "  Covariances shape: (2, 30, 30)\n",
            "  Weights shape: (2,)\n",
            "\n",
            "Initial log-likelihood: -5999.7426\n",
            "\n",
            "Starting EM iterations...\n",
            "----------------------------------------------------------------------\n",
            "Iteration  10: Log-likelihood = -1228.0862, Change = 19.353319\n",
            "Iteration  20: Log-likelihood = -1142.1797, Change = -0.286633\n",
            "Iteration  30: Log-likelihood = -1126.0376, Change = 0.751830\n",
            "Iteration  40: Log-likelihood = -1117.9027, Change = -0.031370\n",
            "Iteration  50: Log-likelihood = -1117.8907, Change = 0.009440\n",
            "Iteration  60: Log-likelihood = -1117.8688, Change = 0.000292\n",
            "----------------------------------------------------------------------\n",
            "✓ Converged at iteration 64\n",
            "  Final log-likelihood: -1117.8683\n",
            "  Log-likelihood change: 0.000073\n",
            "======================================================================\n",
            "TRAINING COMPLETE\n",
            "======================================================================\n",
            "Converged: True\n",
            "Iterations: 64\n",
            "Final weights: [0.68958108 0.31041892]\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TEST 2: Predictions\n",
            "======================================================================\n",
            "\n",
            "Hard predictions (labels) shape: (569,)\n",
            "Unique labels: [0 1]\n",
            "First 20 predictions: [0 1 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 0]\n",
            "\n",
            "Cluster distribution:\n",
            "  Cluster 0: 401 samples (70.5%)\n",
            "  Cluster 1: 168 samples (29.5%)\n",
            "\n",
            "Soft predictions (probabilities) shape: (569, 2)\n",
            "First 5 samples probabilities:\n",
            "[[6.89437841e-01 3.10562159e-01]\n",
            " [2.73791575e-08 9.99999973e-01]\n",
            " [1.59382537e-07 9.99999841e-01]\n",
            " [6.89581079e-01 3.10418921e-01]\n",
            " [4.41521748e-06 9.99995585e-01]]\n",
            "\n",
            "======================================================================\n",
            "TEST 3: Model Score\n",
            "======================================================================\n",
            "Final log-likelihood: -1117.8683\n",
            "Log-likelihood history length: 65\n",
            "\n",
            "======================================================================\n",
            "TEST 4: Convergence Visualization\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAerhJREFUeJzt3Xd4FFXfxvF7UzeUhAAJCRIgFCnSQWMEQRANigh2wQKIUgSRoqKAFPUVQeEBK1awoGJFsSB5EKwRC0QFAUGaAgEUSEJJ3fP+wZM1y6bsZjfZkP1+rosLMnNm9mzOJOTO78wZizHGCAAAAAAAeF2ArzsAAAAAAEBVRegGAAAAAKCcELoBAAAAACgnhG4AAAAAAMoJoRsAAAAAgHJC6AYAAAAAoJwQugEAAAAAKCeEbgAAAAAAygmhGwAAAACAckLoBgAAPrNmzRpZLBbNmDHDYXvjxo3VuHHjCnu9Cy64QBaLxWHb4sWLZbFYtHjxYq/3ozxYLBZdcMEFvu4GPDRkyBBZLBbt3LnT110B4CWEbgCVSmpqqkaOHKnWrVsrPDxcISEhiomJ0UUXXaS5c+fq4MGDTsdYLBZZLBaFhobqn3/+KfK8hw8fVlhYmL1tYQU/hFssFnXp0qXYvn366af2dmX5wXbVqlUaNGiQGjdurLCwMFWvXl2tWrXSiBEjtHbtWrfPB/+zc+dOWSwW9enTx9ddKdHp0k+c/mbMmCGLxaI333zTYXtl/gXE6fbLHACeI3QDqBRsNpvuuusudezYUS+88IJiYmJ0yy236O6771a/fv20b98+3XXXXYqPj9eePXucjg8KClJOTo6WLFlS5PmXLFmirKwsBQUFFduHoKAg/fTTT/rll1+K3P/iiy+WeHxxTpw4oYEDB6p379764IMP1L59e40ZM0a33367zjzzTC1ZskTnnnuuXn31VbfPDZzuzjnnHG3atEljxozxaT9eeeUVbdq0yad9ACRp1qxZ2rRpk8444wxfdwWAl7j/0yMAlIMpU6Zo7ty56tSpk5YuXapmzZo5tVm3bp0mTZqkEydOOO1r2rSpjDFatGiRxo4d67T/pZdeUosWLSRJW7ZsKbIPSUlJ+vTTT/XSSy9p/vz5Dvv+/vtvLV++XJdeeqk+/PBDt97bsGHD9Oabb+qiiy7Sq6++qnr16jnsP3LkiGbNmqUjR464dV6gKqhWrZpatmzp626oYcOGvu4CIEmKjY1VbGysr7sBwIuodAPwud9//12PPvqooqKitGLFiiIDtyR16tRJycnJxd7nOXToUKWmpmrdunUO23/++WetX79eQ4cOLbEfDRo00EUXXaQlS5YoJyfHYd9rr72mnJwc3XLLLa6/MUmrV6/WG2+8oTPPPFPLli1zCtySVKtWLc2ePVvDhw932L5r1y4NGzZMZ5xxhkJCQtSgQQMNGzZMu3fvdjpHwf2oubm5mjFjhho3bqzQ0FCdeeaZevrppx3aPvjgg7JYLHrllVeK7PN7770ni8WiKVOmOGzfsWOHbr31VjVs2FChoaGKjY3VkCFDtGvXLqdzFEzt3LNnj26++WbFxMQoICBAa9askSTl5eVp1qxZatq0qaxWq5o1a6ZZs2Zp+/btslgsGjJkiNM5Dxw4oPHjx6tZs2YKDQ1V3bp1ddVVV2nDhg1ObQvuBz569KjuvPNO1a9fX6GhoWrXrp3eeeedIt93Tk6O/vOf/+jss89WzZo1VaNGDbVu3VoTJkzQ4cOHy9wXX3LnGpKkX375RZdeeqlq1qypiIgIXXrppdqwYUO53mNa3D3WxZk3b54CAgJ04YUXKjMz0779gw8+0IUXXqjIyEhZrVa1adNGjz32mPLz8106b1H3dBe2cuVKnXfeeapWrZrq1KmjwYMHF3s7y/Lly9WzZ09FREQoLCxM7du317x585SXl+eV9i+88ILatGkjq9WquLg43XPPPcrKynLpfRZ27NgxTZ8+XS1btpTValXt2rXVt29fffPNNw7tKsP3DFcVXE+S9MUXX9hvCSpqOrer10zh6eDLly9X165dVbNmTfv/RTk5OXriiSeUlJSkuLg4hYaGKjo6WldeeaXWr1/vcK4hQ4bY/y8aOnSoQ/8Ktynu623RokVKSEhQjRo1VKNGDSUkJBQ5Tb3w19WPP/6oiy66yP51fcUVVxR57nXr1unqq6+2j1dUVJTOPvts/d///V8pn3UApTIA4GOTJ082kszUqVPLdLwk06JFC7N3714TGBhoxowZ47D/jjvuMIGBgWbv3r2mRYsW5tRvfatXrzaSzIgRI8zSpUuNJPPOO+84tGnbtq0566yzzL59+4wk06NHD5f6dsMNNxhJ5rnnnnPrPW3ZssVERUUZSaZfv37m3nvvNZdddpmRZKKiosyWLVsc2vfo0cNIMldddZWJi4szw4cPN6NGjTJ16tRxev3t27cbi8ViLrrooiJfe8CAAUaS2bRpk33bd999ZyIiIkxQUJAZMGCAufvuu80111xjgoKCTHR0tPnjjz8cziHJtGnTxsTFxZn27dubO++804wYMcL89NNPxhhjbrrpJiPJNGnSxEyYMMGMHj3aREVFmX79+hlJZvDgwQ7n27Ztm2nQoIGRZC6++GIzceJEc9NNN5lq1aqZ6tWrm++++86hfaNGjUz9+vVNYmKiadmypRkzZoy55ZZbTLVq1YzFYjGfffaZQ/vjx4+brl27GkmmefPm5o477jB33XWX6d+/v6lWrZpZv359mfviTTt27DCSTFJSUqlt3b2GUlNTTc2aNU1AQIC5+uqrzX333WcuuugiExERYbp3724kmR07dni9nwVff9OnT3fY3qhRI9OoUSP7xzabzdx9991GkrnmmmtMdna2fd+9995rJJkzzjjD3HLLLWb8+PGmS5cuRpK5+uqrXXq9gq+hwhYtWmQkmSuuuMKEhISYq666ykycONGcffbZRpLp2rWr0/uZO3eukWRq165tRo4caSZOnGiaN29uJJkBAwYYm83mUfsHHnjASDL16tUzY8aMMePHjzcNGza0j62r35tOnDhhzjnnHCPJdOrUyUyaNMkMGTLEhIWFmcDAQPPWW2/Z21aG7xnFmT59upFk3njjDWPMyWuvYFujRo3M9OnT7X8Kfx27c80UXAeXXnqp/f3cc889ZuTIkcYYY/bt22cCAgJMjx49zPDhw82kSZPMNddcY0JDQ43VajXff/+9/Vzvv/++6d+/v5Fk+vfv79C/AoMHDy7y6+2OO+6w93ns2LFm7Nix5owzzjCSzNixYx3aFlznl156qQkLCzOXXnqpmThxounVq5eRZJo2bWpOnDhhb79+/XoTGhpqqlWrZgYOHGjuvfdeM3LkSNO9e3fTsGHDEscAQOkI3QB8rmfPnkaSWbVqVZmOLwjdxhhz2WWXmdq1a5usrCxjjDFZWVmmdu3apl+/fsYYU2rozs7ONnXq1DGXXnqpff/3339vJJm5c+e6HbobN25sJJlt27a59Z4KPifPPvusw/annnrKSDK9evVy2F4QGBISEkx6erp9++bNm01QUJD981OgW7du9l9EFPbPP/+YkJAQ06VLF/u2nJwc07hxY1OzZk2zbt06h/ZfffWVCQwMNJdddpnDdklGkhk6dKjJy8tz2Pff//7XSDIdOnQwx44ds2/fu3evqVevXpGh+7zzzjOBgYFmxYoVDtu3bNliatasadq2beuwvVGjRvYfaguHs4LXPjUMTpw40UgyN910k1N/jxw5YjIzM8vcF29yJ8y6ew1169bNSDJLlixx2H7//ffbx9NXoTs3N9fcfPPNRpIZPXq0yc/Pt7dbuXKl/bWOHj1q326z2czIkSOdfolWltAdFBRkvv76a/v2vLw8c8EFFxhJJiUlxb5927Zt9lC5e/du+/asrCz75/eVV14pc/utW7eaoKAgc8YZZ5j9+/fbt6enp9u/t7n6vWnmzJlGkrnhhhscgv26detMSEiIqVWrlsnIyLBv9+X3jJKcGroLn6+4z4W710zBdRAQEGCSk5OdzpeVlWX++usvp+0bNmwwNWrUML1793bYXnC+RYsWFdm/okL3F198YSSZVq1amSNHjti3Hzp0yJx55plGkvnyyy/t2wuuc0nmzTffdDh/wS89C3/OJkyYYCSZZcuWOfXn77//LrKfAFxH6Abgc61atXKqkhRYvXq1QyVg+vTpZvXq1Q5tCofu9957z+GHjDfffNNIMu+//74xpvTQbYwxY8eONYGBgWbPnj3GGGNGjhxpgoODzYEDB9wO3Var1Uiy/xLAFbt27TKSTOvWrZ2qXPn5+aZly5ZGksMP6QWB4fPPP3c6X8G+wj9AP/vss/ZfJBT29NNPG0lm/vz59m0Fn9MHHnigyP5eeeWVJiAgwCHsSzIhISHm4MGDTu2HDBliJJn33nvPad/DDz/sFLrXrVtnJJlbbrmlyNcv+GHx119/tW8rCN3bt293at+oUSNTu3Zt+8e5ubmmZs2aJiIiwhw6dKjI1/CkL97kaph19xrauXOnkWTat2/vdK6jR4+ayMhIn4XuY8eOmUsvvdRIMjNnznQ6/vLLLzeSzK5du5z2HTlyxFgsFnPVVVeV+nolhe6bb77Z6dwF+x5//HH7toIq9OzZs53af/PNN06/7HC3fUFQPvXr1hhjXn31Vbe+NzVp0sQEBwebP//802nfbbfd5hT4ffk9oyRlCd3uXjOFZzy4q1+/fiYkJMTk5OQ4nc+d0H3LLbcYSWbp0qVO7ZcsWeL0fangOu/evbtT+4J9EyZMsG8r+N516iwgAN7BQmoAKrU1a9Zo5syZTtuLexTMZZddpujoaL300ku67rrr9NJLLyk6OlqXXXaZy695yy236PHHH9fLL7+s8ePH680339Rll12mqKgopaWllfWtuCw1NVWS1KNHD6d7TAMCAtS9e3dt3rxZqampiouLc9jfuXNnp/M1aNBA0skF22rWrClJuvbaazV27Fi9+uqrmjBhgr3ta6+9pqCgIA0cONC+7bvvvpN0cgG6ou67TUtLk81m0++//+7wyLX4+HjVrVvXqf3PP/8sSerWrZvTvq5duzptK3j9/fv3F/n6mzdvtv/dpk0b+/ZatWopPj7eqX2DBg2UkpLicHxmZqZ69+6tyMhIp/be6MupUlNTtWzZModtjRs3LvJe9rJw9xoqGJOiPv/Vq1dXhw4dtHr1avu2I0eOOC02KMnl+7JddeLECV144YX6/vvvtXDhQo0YMcKpzXfffafq1avrpZdeKvIcYWFh9nEpq9K+rgoU3L9b1PenxMREWa1W+9iUpX3BOJ1//vlO7YvaVpyMjAxt375drVq1sr+Pwnr27Knnn39eqampuummmyT59nuGt5X1mjnnnHOKPWdqaqrmzJmjr7/+WmlpacrNzXXY//fff3u0OFpJ10rPnj3tfTiVq9futddeq/nz5+uKK67Qddddp4suukjdu3dnBXXASwjdAHyuXr162rRpk/bu3eu0ivGMGTPsP7S9+eabDj/YFSU4OFg33nij5s+fr2+//Vb//e9/NX78eLce9dW+fXt16tRJixYtUsOGDXXkyBG3F1ArEBMTo507d2rPnj1q0qSJS8dkZGRIUpGLrkmy/+BW0K6w8PBwp20F773w4kC1atXSZZddpnfffVe//fabWrdurT/++EPffvutLr30UkVHR9vbHjp0SJKKfRxbgWPHjjl8XFz/MzIyFBAQUOQP10UdU/D6H3/8sT7++GOXXz8iIqLIdkFBQbLZbPaP09PTJcmlHy7L2pdTpaamOv0yqUePHl4L3e5eQwV/Fx73wopacb+oX4Z5O3RnZmZq/fr1qlOnjj1YnOrQoUPKy8srsj8FShuP0rj6dVXS591isahevXoOjzx0t33BtVrUOBU31kUpy/cYX37P8LayXjPF9e/bb79Vr169JEkXX3yxmjdvrho1ashisWjZsmX6+eeflZ2d7VGfC75vRkVFFdkvi8Xi0f8JCQkJWrNmjR5++GG9/vrrWrRokSTp7LPP1uzZs4v9+gPgGlYvB+Bz5513niQ5VNI8MWzYMNlsNl177bWy2WwaNmxYmc6xdetWTZo0SfXr19cll1xSpr4UVA5XrVrl8jEFPyTt37+/yP0F1faifphyR0EFq+D54K+99prD9lP7s3z5cpmTtyUV+adHjx4OxxW3EnR4eLhsNpv+/vtvp31FveeC13/iiSdKfP3Bgwe78/btatWqJUlFPv+9vPoyZMgQp2PcXaXZlX66eg0V/H3gwIEi2596nsaNGxf5vr0tOjpaH3zwgTIzM3XBBRcU+bi/8PBw1alTp8Tx2LFjh9f7VpSSPu/GGO3fv9/h69bd9gW/SCpqnIoba3f7KRX/PcZX3zO8razXTHH9+7//+z9lZ2frv//9rz788EPNnTtXM2fO1IwZMxQTE+O1PttsNh08eNBp34EDB2SM8fj/hPPPP1+ffvqpDh8+rNWrV2vChAn69ddf1bdvX23fvt2jcwP+jtANwOcGDx6sgIAAPffcc0UGMXe1bt1aCQkJ2rNnj84991y1atXK7XMMGjRIVqvV/viawMDAMvWlIPDPnTu3yOeLF1ZQCenQoYMk6csvv3QKMsYYffnllw7tyurSSy9VnTp19Prrr8tms2nJkiWqWbOm+vfv79AuISFBkhymZHuiffv2kuT0WCLpZMXoVN5+/VO1aNFC4eHh+uGHH5weDVbRffEWd6+hgjEp6vN//Phx+7RmX0hKStKHH36oI0eOqGfPnk7BOyEhQf/884+2bt3qox7+q2PHjpJU5C9Q1q5dq6ysLIevW3fbF4zTV1995dS+qG3FCQ8PV5MmTbRt27Yif9lU0J9Tv8f46ntGWQQEBBT7uDhvXzN//PGHateu7XTLzPHjx50eYSnJ/v+Jq4+zk0q+Voobr7IKCwvTBRdcoLlz52ry5Mk6ceKEkpOTvXJuwF8RugH43Jlnnql77rlHBw4c0CWXXKJt27YV2a7w/Weleemll/T+++/rxRdfLFOfatWqpc8++0zvv/++xo8fX6ZzSCfvtRs4cKC2bNmiK6+8ssgKVUZGhiZPnqznnntOktSwYUP17NlTGzdudLrn8LnnntOmTZvUq1cvp/u53RUcHKzrrrtOu3fv1pw5c7R161ZdddVVCgsLc2jXv39/NWzYUPPmzbOHtcJyc3P19ddfu/y6N9xwgyTpgQcecPhFRFpamhYsWODU/pxzzlFCQoLeeOMNLV261Gm/zWbTF1984fLrnyooKEgjRoxQenq67rzzTqcfhNPT03X06NEK6Yu3uHsNNWrUSF27dlVqaqrT+3r00Uft04V95aKLLtLy5ct15MgRXXDBBQ73244dO1bSybUYinpudlpamjZt2lQh/Rw0aJCCgoI0b9487d271749JydHkyZNkiSHWwjK0j4wMFDz5s1z+F6SkZGhhx56yK2+Dh48WLm5ubrvvvscfjHzyy+/aPHixYqIiNCAAQMcjvHV94yyqF27tv76668i93n7mmnUqJEOHz6sjRs32rfl5+frrrvuKrIyXbt2bUnSn3/+6fJrFMyemTlzpsM08vT0dPs0+bLO9pFO/oKkqGe9F8yGsFqtZT43AO7pBlBJ/N///Z9ycnI0b948tWzZUt27d1f79u1VrVo1HThwQL/88ou+//571ahRw6Xf5rdu3VqtW7f2qE/du3f36PgCL774oowxevPNNxUfH6+LL75YZ555powx2rp1q1atWqXMzEz7lE1JeuaZZ9StWzfddtttWr58uVq3bq2NGzfqww8/VFRUlJ555hmv9O2mm27S008/rWnTptk/PlVoaKjeeecdXXLJJerRo4d69eqltm3bymKxaNeuXfrqq69Up04dlxer6t27twYNGqTXX39dbdu21YABA5Sdna233npLCQkJWr58uQICHH8n/MYbb6hnz566/vrrNX/+fHXq1ElhYWHavXu3UlJSdPDgwSJ/YHTVAw88oO+++06vvvqqvvvuO11yySUKDQ3V9u3btWLFCn399df26668++KKX3/9tdj7v1u2bKl7773X7WvoiSeeUPfu3XXDDTfo3XffVbNmzbRu3Tp999136t69u7788kuncfFGP1114YUX6qOPPlK/fv3Us2dPff7552rVqpX69Omj+++/Xw8++KCaNWumPn36qFGjRvrnn3+0bds2ffXVV3rooYfKNOPFXU2bNtXs2bM1ceJEtWvXTtdee62qV6+u5cuXa8uWLerfv79uvPHGMrdv1qyZpk2bpunTp9vbBwUF6d1331W7du2KnH5fnHvuuUcff/yxXn31VW3atEkXXnihDhw4oKVLlyovL0/PP/+8feHFwnzxPaMsevXqpbfeeksDBgxQx44dFRgYqMsvv1zt2rXz+jVzxx13aOXKlerWrZuuvfZaWa1WrVmzRnv27NEFF1zgVJ1OTExUWFiY5s+fr8OHD9vv0546dWqxr9G9e3fdcccdeuKJJ9SmTRtdddVVMsbo3Xff1V9//aWxY8d69H/W7NmztXr1anXv3l3x8fGyWq1at26dVq1apSZNmuiKK64o87kB6JRnYwCAj61bt84MHz7ctGzZ0tSoUcMEBwebevXqmV69eplHH33U4dm0BVTokWGlceWRYSVx95FhhSUnJ5uBAweaRo0aGavVaqxWq2nevLm59dZbzdq1a53a79y50wwdOtTExsaaoKAgExsba4YOHWp27tzp1Laoxx0VKOrxM4U1b97cSDINGjRweP7xqf766y9z5513mubNm5vQ0FATHh5uWrVqZW699VanZ6yX9jnKzc01Dz74oImPjzchISGmSZMm5uGHHzZr1641ksydd97pdMyhQ4fM1KlTTZs2bUxYWJipUaOGad68uRk0aJDT48cKP+P5VMV9rrKyssxjjz1mOnToYD9/69atzcSJE83hw4fL3BdvKngUV0l/Cn/e3bmGjDFm/fr1JikpydSoUcPUrFnTXHLJJebXX381l112mZHk9HnwRj9deU53YatXrzbVq1c39erVMxs3brRvT05ONv369TNRUVEmODjYxMTEmMTERPPggw86PF6vLI8MK+rRTsWdxxhjPvjgA9OjRw9Ts2ZNExoaatq2bWvmzp1rcnNzi/x8udv++eefN61btzYhISGmQYMG5q677jLHjx93+3vT0aNHzf3332/OPPNM+7O5L7nkEvPVV1+VeJwvvmcUp7hHhu3bt89ce+21pm7duiYgIKDIcXT1mintEV/GGPPOO++YTp06mWrVqpm6deuaa6+91vzxxx/Ffv/9+OOPzdlnn23CwsLsXxMFSvqe/dJLL5mzzz7bVKtWzVSrVs2cffbZ5qWXXnJqV9L1WfD1WfjRjCtWrDA333yzadGihalZs6b9+9/kyZPdfowbAGcWY8ph5RMAAMrghRde0G233aann35ao0aN8nV3oJPTZJs2baoTJ064tVgXAAA4iXu6AQAVLi0tzWmBrz179uihhx5SYGCgW89Vh3fk5eUVuZDhI488ol27djnd3wsAAFzDPd0AgAr3yCOP6OOPP9b555+v6Oho7d69Wx999JEyMzM1Y8YMjxeJg/uOHj2qM844QxdddJHOPPNM5ebmau3atfrhhx8UGxvr9WdwAwDgL5heDgCocCtWrNC8efP0888/6/Dhw7JarWrXrp1uv/12DRo0yNfd80s5OTkaN26cPv/8c+3du1dZWVmKjY3VJZdcovvvv19nnHGGr7sIAMBpidANAAAAAEA54Z5uAAAAAADKCaEbAAAAAIBywkJqFcBms2nv3r2qWbOmLBaLr7sDAAAAAPCQMUaZmZmqX7++AgKKr2cTuivA3r17WYkXAAAAAKqgP//8Uw0aNCh2P6G7AtSsWVPSycEIDw/3cW+c2Ww2HTx4UFFRUSX+hgZVD2Pvnxh3/8XY+yfG3X8x9v6Jca84GRkZiouLs+e94hC6K0DBlPLw8PBKG7qzsrIUHh7OF6afYez9E+Puvxh7/8S4+y/G3j8x7hWvtFuIGQUAAAAAAMoJoRsAAAAAgHJC6AYAAAAAoJwQugEAAAAAKCeEbgAAAAAAyslpG7r/7//+T+edd56qVaumWrVqFdlm9+7d6tu3r6pVq6bo6GjdfffdysvLc2izZs0aderUSaGhoWrWrJkWL17sdJ6nnnpKjRs3ltVqVUJCgr7//vtyeEcAAAAAgKrmtA3dOTk5uuaaazRq1Kgi9+fn56tv377KycnRt99+q5dfflmLFy/WtGnT7G127Nihvn37qmfPnkpNTdW4ceN066236rPPPrO3Wbp0qSZMmKDp06dr3bp1at++vZKSknTgwIFyf48AAAAAgNPbaRu6Z86cqfHjx6tt27ZF7l+5cqV+++03vfbaa+rQoYMuueQSPfjgg3rqqaeUk5MjSVq4cKHi4+M1d+5ctWrVSmPGjNHVV1+t//znP/bzzJs3T7fddpuGDh2q1q1ba+HChapWrZpeeumlCnmfAAAAAIDTV5CvO1BeUlJS1LZtW9WrV8++LSkpSaNGjdLGjRvVsWNHpaSkqHfv3g7HJSUlady4cZJOVtN/+ukn3Xffffb9AQEB6t27t1JSUop97ezsbGVnZ9s/zsjIkHTyQfU2m80bb8+rbDabjDGVsm8oX4y9f2Lc/Rdj758Yd//F2Psnxr3iuPo5rrKhOy0tzSFwS7J/nJaWVmKbjIwMnThxQocPH1Z+fn6RbTZv3lzsa8+aNUszZ8502n7w4EFlZWWV6f2UJ5vNpvT0dBljFBBw2k5+QBkw9v6JcfdfjL1/Ytz9F2Pvnxj3ipOZmelSu0oVuu+9917Nnj27xDabNm1Sy5YtK6hHZXPfffdpwoQJ9o8zMjIUFxenqKgohYeH+7BnRbPZbLJYLIqKiuIL088w9v6JcfdfjL1/Ytz9F2Pvnxj3imO1Wl1qV6lC98SJEzVkyJAS2zRp0sSlc8XExDitMr5//377voK/C7YVbhMeHq6wsDAFBgYqMDCwyDYF5yhKaGioQkNDnbYHBARU2gvfYrFU6v6h/DD2/olx91+MvX9i3P0XY++fGPeK4ernt1KF7qioKEVFRXnlXImJifq///s/HThwQNHR0ZKk5ORkhYeHq3Xr1vY2n3zyicNxycnJSkxMlCSFhISoc+fOWrVqlQYMGCDp5G+OVq1apTFjxnilnwAAAACAquu0/dXH7t27lZqaqt27dys/P1+pqalKTU3V0aNHJUkXX3yxWrdurZtuukk///yzPvvsM02dOlWjR4+2V6FHjhyp7du365577tHmzZv19NNP66233tL48ePtrzNhwgQ9//zzevnll7Vp0yaNGjVKx44d09ChQ33yvgEAAAAAp49KVel2x7Rp0/Tyyy/bP+7YsaMkafXq1brgggsUGBiojz76SKNGjVJiYqKqV6+uwYMH64EHHrAfEx8fr48//ljjx4/XggUL1KBBA73wwgtKSkqyt7nuuut08OBBTZs2TWlpaerQoYNWrFjhtLgaAAAAAACnshhjjK87UdVlZGQoIiJC6enplXYhtYJp+Nz34V8Ye//EuPuv8h77fJvR9zsO6UBmlqJrWnVOfG0FBli8ekxFvEZV69fa7X9r218H1axBlBKa1PWr9+7v/XJn7Kvae/fnfvnr17wvuJrzTttKNwAA7qqMP1hU7A/g/2jbX4fU7Gig138AX7Fhn2Yu/0370v99NGZshFXT+7VWnzaxXjmmIl6javdrhx+/d3/vV8ljX7Xfuz/3y3++5is7Kt0VgEo3KivG3nWVOUhVtqpXWftV3q9RGX+wqKw/vJSl/ajX1unUHygKRuOZGzs5HefuMRXxGvSr8r0G/aoa/fLn906/KuYYX3E15xG6KwChG5WVv459VQhr9Kt8Q6E///Dibvt8m1HXRz5XWkaWihNVI1SLbzlbkmSMlJNn022v/Kh/juUUe0zt6iGaf20HWQIkm81o/NKfdeh4Ce2rBeuRK9spIMAiIyk/36b73v9Vh4/nFntMZLVgPdi/jSwWy//ei03TPtyoIyUcU6tasKZf1loBARbZbEYzl/+mIydKaB8WrGn/ay+dfC8PfFS+x7jUvtD7KHiNUt+Lu++9WrBm9DvL4TVmfLixXI9xtb0n770sx1TEa7h8jLvXSkVcj5X164R+Vbp+WSTFRFj19aRelWKqOaG7EiF0o7KqCmNfEQHaH4NUVepXvs2o2+zPHcb81OPqhVv1ydjzZWSUk2dT/6e+0YHM7CLbS1KdGiF6elCnk+c3Rnl5RncuTdXhEkJhrbBgTe7bSjJSns2mRz7drIysvGLb17QGaXj3JpKRjE4e89LXO3U0u/hjqocE6uouDWT532cjz2bTe+v26HhOfrHHWIMD1KtltIw5GTq/+P1vZefZim0fGGBRVI0Q5eQbZefm60Ruvmz8JAEAqEBv3HauEpvW8XU3CN2VCaEblVVlHHt3QnR5B2hXwlrh37a6296d1/ji7p4yMsq3GWXn2dTnP19qfwmhMLpmqN4ddZ6CAi2y2aQrni45RNarGar3bu+qgssgL9/oqme+LfGYguqlRRbZjFFuvk23vlxy9TKyWrAevqKt/TXu/2BDib8BD7cGaUSPpjLGKM928jUWf7tTx7KLD5GhQQFq1yDCHgrTj+dqXwlVWAAAcHpZcH0H9e9whq+7QeiuTAjdqKwq29i7E6LdCdB5+Tb9fTRHlz3xlf4+WnwgDAsOVM+WUcrJsykr16YDmVn6ff/RUvttDQpQQIBFufk25eaX/i01JDBAQYEna5H5xigrt/iqIlAZRYQFq1a1YIUGBSg332jH38dKPaZniyjF1gpToMWiAxlZ+uy3/aUeM6BDfcXVrqa/Dh/X++v3ltr+2s4N1LBONVksFu0+dFxLf/iz1GNuTGioRnWqy2KRdv5zTK99t7vUYwYnNlLjutW18+9jejllV6nth5zXWPF1q0uSdvx9TIu/3Vmux7jafnBiI4fXcOW9uPvebz73ZHtJ2vn3Mb3yXfke42r7gvdR8BruvHd3jykYE3faS+6NibvHuHutVMT1WFm/TuhX5ezX6VbpZvVyAOXG3ap1USE6LT1Lo15b5xSip3+w0amtJPu2O95Yrwa1NuvQ8Vyll1BJLexEbr4++TXNtTdXSFYJU3GLkpNvUwmzfeFF1uAABVosOubCJ7x9XITqVg9V+olc/bjrcKntL20To7ja1RQQYNG+Iye0LLX0UHhL18ZqFl1TO/85que+3FFq+7suPlOtYsMVYLFoc1qGZq/YUuoxMy8/S+0aRMhisWjDnnRNXbah1GMeH9hBXRrVVuqfR3T7knWltl94Y2f7DzsFszXS0rOK/JosmK3xwuCznWZ4lHbM3Gs72GeRfLf9UKntZ13VzuE1vvz9YKnHzOzfxuGYVZsOlHrMtH5n2fu18rf9pba//7LWDq/x2ca0cj3G1fYF76PgNVx5L+6+9+mXO75G8qbyPcbV9p689/L8fFVUv9y9VirieqysXyf0q3L265z42kXsrbx8X9oCUCWt2LBP3WZ/roHPf6c730zVwOe/U7fZn2vFhn1ObfP/t/BLcSHaSLrzzVRd9vhXSpy1Si3u/7TEqdWSTlbf/jnucuD2xBm1rGpRr6biIsNcah8XGaYz69VQ8+gaqh9hdemYM+vV0DnxtXVe0zpqe4ZrM2YS4iN1SZsYndM40qX25zQ+2f7StjFKiHftmJ4tojQooaFuPLehklrXc+mY68+O032XtNSN5zZ0qf2Ei87Ui4O7aNHQszX50pYuHfPqLedox6xLtfnBS/TLjCTFRljtsyBOZdHJGRXvjeqqF4ecraUjEl1q/8SgTrrv0laa1Kel5l7bwaVjpvRtrUEJDTWpTyuX2o+6oJkubFVPPVtGa3j3pi4dc+O5jdSxYaQ6xNXSwHMaunRM37b1Vb9WmJLOinGpfeEfdgIDLJrer7V9/6ntJWl6v39/oCrLMRXxGvSr8r0G/aoa/fLn906/KuaY0wHTyysA08tRWbk79q5Wrkua+m0kjenZVLG1wrT3yAntOXxCm/dlavP+TK+8p8JCgwJUL9yq2tVDFCBp3Z9HSj3m8es76LxmdWUNDlRwgEUXPLam1N+2nnpPt6vtJdcrfp4c4+/9kv69JiU5HFfQorgF3lxtX1lfo6L6VXBcVVjpnn5VvtegX1WjX/783ulX1X1ON/d0VyKEblRG7j6v2dVvfuknctVr7hr9U8K902VlkVS3ZqjCggO1+9DxUtsXvt+nKoU1+lUxodCff3gp6w87VeWZ7lWtX+58r69q793f++XO2Fe19+7P/fLXr3lfIHRXIoRuVDbeWvW7QI8zo5Sbb9MfB49qf0bJ0749seTWBHVtVrfCAnTh4/w1SFWlfkmV8weLqvQDOCon/p/3X4y9f2LcKw6huxIhdKO8eWPBslODZ26+TXuPnNDOv4/pjjfWl/g84bK4rkucLm0XqzNqWVUv3KqL//OlWyG6IqfASpU7SFW2qldZ+1UVfwNe2fD93j8x7v6LsfdPjHvFIXRXIoRulCd3QmRpz4SWTj7OKqpmiPalZ8nm5neH2tVDVLdGiEuP2Tr1UQ9lnWZcUVNgqxK+5v0XY++fGHf/xdj7J8a94vDIMOA05umCZYUfs3Vukzra8fcx7frnuL7aerDEwC2dfJzVniMltynKw1e00aCERi5P/T71UQ992sTqmRs7OYXomBJCdJ82sbqodYzbATowwFIpnu0IAACAqo/QDVQyrlZvS3vMlqQS78MuiTU4QM2ia6hh7WoKDLBo+c/Oj/k6VXzdGpL+fdTDqNfW2VcrL1Daox7KEqIJ0AAAAKjMCN1AJVJa5frpGzqpY8NIbUrL0Gcb0kqtWpf13pFFQ85xWPX7x52H3apcl6VqXYAQDQAAgKqE0A2UM1enirtSub799XVydxWG5tE1dHZ8bTWuU01xkdV0/wcb9M/RHJcDdFkr12Wd+g0AAABUJYRuoBy5MlU832a0+9BxfZi6t/TKdRlK1w/0b+NQObZYVKYAXZbKNVVrAAAA+DtCN+AGbzyaa196lka+tk6JTeroWE6eft+fqaxcm8t9aBlTUz3OjFKLejX18Keb3KpaS2UP0FSuAQAAAPcRugEXuftormkfbCzxnuqU7f+UqR/T+51lrx5XCw30aMEyd5/XTOUaAAAAcA+hG3BBaQuczbu2vepFWPXzn+lK/fOwvt9xSIeP57p07sZ1qqlFTE01r1dTr323S0eKOa48Fiw7t0kdNamRr+joOgqgYg0AAAB4HaEbKIUrC5yNf+vnMp370avb6ZoucfaP29QP16jX1jmcW2LBMgAAAOB0RegGSvH9jkOlLnB2KmtwgEv3aTeIrObwMQuWAQAAAFULoRt+rbSF0Y5l52n5z3tcOlfXZnU0oMMZ6hBXS43qVFePR1e79WzrAlSuAQAAgKqD0A2/VdzCaNMua62omqF6+8e/9NEve3UsJ9+l843p2dyh2lyWZ1sXoHINAAAAVA2Ebvilkh7nNWrJOrfO5e1HcwEAAACoOgjd8DslLYx2qhqhQerXvr7iIsP06GdbJJXt0VxMFQcAAAD8E6EbfsfVhdFuv6CpxvRqpmohJ79MmkRVL/OjuZgqDgAAAPgnQjf8Sr7N6NMN+1xq2yKmpj1wS1StAQAAALiP0I0qo6SVyG02o49/3acFq7Zq24GjLp0vuqbVaRtVawAAAADuIHSjSihuJfL7+7aWkbRg1e/6fb9rYbukx3kBAAAAgDsI3TjtlbQS+e2vO69E3rlRpLo1q6vHV22V5P7jvAAAAADAVYRunNbcWYm8U8NaGn/RmerWrK4sFotaxdbkcV4AAAAAyhWhG6c1V1civ/eSlhrRvYksln+r1yyMBgAAAKC8EbpxWjuQWXrglk7e3104cBdgYTQAAAAA5SnA1x0APFErLNildkWtRA4AAAAA5Y1KN05bW/dn6qGPfyuxDSuRAwAAAPAlQjdOS2//+KemfbBRJ3Lzi23DSuQAAAAAfI3p5TitHM/J08S3ftbd7/xiD9wtY2pqer/Wio1wnEIeE2HVMzd2YiVyAAAAAD5DpRuVUr7NOK0qvu3AUY1+fZ22HThqbzfwnDhN73eWrMGBujmxMSuRAwAAAKhUCN2odFZs2Of0/OyIsGAdz8lTbv7JJ3JXDwnUw1e2Vf8OZ9jbsBI5AAAAgMqG0I1KZcWGfRr12jqZU7ann8i1/7tVbLieGtRRTaJqVGznAAAAAMBNhG5UGvk2o5nLf3MK3IVVCwnUOyMTVT2USxcAAABA5cdCaqg0vt9xyGFKeVGO5+Trl7/SK6hHAAAAAOAZQjcqjQOZJQdud9sBAAAAgK8RulFpRNe0lt7IjXYAAAAA4GuEblQa7eMiFBJY/CVpkRQbcfJRYAAAAABwOiB0o1Kw2YzueecX5eTbitxf8LTt6f1a8+xtAAAAAKcNQjcqhYc/2aSPftknSQoOtKhO9RCH/TERVj1zYyf1aRPri+4BAAAAQJnw3CX43AtfbdcLX++QJAUGWLTwxs66oEW0vt9xSAcysxRd8+SUcircAAAAAE43hG741Aepe/TQx5vsH//fgDa6sFU9SVJi0zq+6hYAAAAAeAXTy+Ez32z7W3e9/bP94/G9z9T15zT0YY8AAAAAwLsI3fCJjXvTNeLVn5SbbyRJA8+J09gLm/m4VwAAAADgXUwvR4XItxn7PdoWSQ989JuOZudJknq3qqcH+7eRxcI92wAAAACqFkI3yt2KDfs0c/lv2pee5bSvU8NaemJgRwWV8HxuAAAAADhdEbpRrlZs2KdRr62TKWb/oHMaKiwksEL7BAAAAAAVhfIiyk2+zWjm8t+KDdySNDf5d+XbSmoBAAAAAKcvQjfKzfc7DhU5pbywfelZ+n7HoQrqEQAAAABULEI3ys2BzJIDt7vtAAAAAOB0Q+hGuYmuafVqOwAAAAA43bCQGsrNrkPHStxvkRQTYdU58bUrpkMAAAAAUMGodKNcfLYxTZPf+7XY/QVP5J7er7UCA3g+NwAAAICqidANr/v2j791xxvrVbAoec+WUYqJcJxCHhNh1TM3dlKfNrE+6CEAAAAAVAyml8Orfv0rXcNf+Uk5eTZJ0hUdz9Dca9rL6ORq5gcysxRd8+SUcircAAAAAKo6Qje85o+DRzV40fc6mp0nSerVMlpzrm6ngP+F68SmdXzZPQAAAACocEwvh1fsSz+hm1/8XoeO5UiSzm4cqacGdVJwIJcYAAAAAP9FIoLHDh/L0U0vfq89R05IklrFhuuFwWcrLCTQxz0DAAAAAN9iejnclm8z9vuzw63B+s9/f9e2A0clSY3qVNPLt5ytiLBgH/cSAAAAAHyP0A23rNiwTzOX/6Z96VlO+6Jrhuq1YQmKrmkt4kgAAAAA8D+EbrhsxYZ9GvXaOpli9g/v0URxtatVaJ8AAAAAoDLjnm64JN9mNHP5b8UGbkl68asdyreV1AIAAAAA/AuhGy75fsehIqeUF7YvPUvf7zhUQT0CAAAAgMqP0A2XHMgsOXC72w4AAAAA/AGhGy5xdXE0FlEDAAAAgH8RuuGSc+JrKzbCKksx+y2SYiOsOie+dkV2CwAAAAAqNUI3XBIYYNH0fq2L3FcQxKf3a63AgOJiOQAAAAD4H0I3XNanTayeubGTwq2OT5qLibDqmRs7qU+bWB/1DAAAAAAqJ57TDbf0aROrHX8f0+wVWyRJ43s315hezalwAwAAAEARqHTDbbn5/z6Lu12DWgRuAAAAACgGoRtuy8rNt/87NIhLCAAAAACKQ2KC27LzbPZ/hwYH+rAnAAAAAFC5EbrhNirdAAAAAOCa0zIx7dy5U8OGDVN8fLzCwsLUtGlTTZ8+XTk5OQ7tfvnlF51//vmyWq2Ki4vTnDlznM719ttvq2XLlrJarWrbtq0++eQTh/3GGE2bNk2xsbEKCwtT7969tXXr1nJ9f5Vd4Uq3Nfi0vIQAAAAAoEKclolp8+bNstlsevbZZ7Vx40b95z//0cKFCzV58mR7m4yMDF188cVq1KiRfvrpJz366KOaMWOGnnvuOXubb7/9VgMHDtSwYcO0fv16DRgwQAMGDNCGDRvsbebMmaPHH39cCxcu1Nq1a1W9enUlJSUpKyurQt9zZeIwvTyI6eUAAAAAUJzT8pFhffr0UZ8+fewfN2nSRFu2bNEzzzyjxx57TJK0ZMkS5eTk6KWXXlJISIjOOusspaamat68eRo+fLgkacGCBerTp4/uvvtuSdKDDz6o5ORkPfnkk1q4cKGMMZo/f76mTp2q/v37S5JeeeUV1atXT8uWLdP1119fwe+8cnCYXk6lGwAAAACKdVqG7qKkp6erdu3a9o9TUlLUvXt3hYSE2LclJSVp9uzZOnz4sCIjI5WSkqIJEyY4nCcpKUnLli2TJO3YsUNpaWnq3bu3fX9ERIQSEhKUkpJSbOjOzs5Wdna2/eOMjAxJks1mk81mK/IYX7LZbDLGuNy37EKhOyTQUinfE1zj7tijamDc/Rdj758Yd//F2Psnxr3iuPo5rhKhe9u2bXriiSfsVW5JSktLU3x8vEO7evXq2fdFRkYqLS3Nvq1wm7S0NHu7wscV1aYos2bN0syZM522Hzx4sFJOS7fZbEpPT5cxRgEBpVeuM4//+x4yDv2jLBZTO225O/aoGhh3/8XY+yfG3X8x9v6Jca84mZmZLrWrVKH73nvv1ezZs0tss2nTJrVs2dL+8Z49e9SnTx9dc801uu2228q7iy657777HCroGRkZiouLU1RUlMLDw33Ys6LZbDZZLBZFRUW59IVps2yTJFks0hmx9WSxWMq7iygn7o49qgbG3X8x9v6JcfdfjL1/YtwrjtVqdaldpQrdEydO1JAhQ0ps06RJE/u/9+7dq549e+q8885zWCBNkmJiYrR//36HbQUfx8TElNim8P6CbbGxsQ5tOnToUGwfQ0NDFRoa6rQ9ICCg0l74FovF5f4VLKQWGhSgwEAWUjvduTP2qDoYd//F2Psnxt1/Mfb+iXGvGK5+fitV6I6KilJUVJRLbffs2aOePXuqc+fOWrRokdMbTkxM1JQpU5Sbm6vg4GBJUnJyslq0aKHIyEh7m1WrVmncuHH245KTk5WYmChJio+PV0xMjFatWmUP2RkZGVq7dq1GjRrl4bs9ff0bugncAAAAAFCS0/JXH3v27NEFF1yghg0b6rHHHtPBgweVlpbmcJ/1oEGDFBISomHDhmnjxo1aunSpFixY4DDt+84779SKFSs0d+5cbd68WTNmzNCPP/6oMWPGSDr5G6Jx48bpoYce0ocffqhff/1VN998s+rXr68BAwZU9NuuNAoWUgvlXm4AAAAAKFGlqnS7Kjk5Wdu2bdO2bdvUoEEDh33GGEknVxlfuXKlRo8erc6dO6tu3bqaNm2a/XFhknTeeefp9ddf19SpUzV58mQ1b95cy5YtU5s2bext7rnnHh07dkzDhw/XkSNH1K1bN61YscLl+ftVUUGl2xpMpRsAAAAASmIxBSkV5SYjI0MRERFKT0+vtAupHThwQNHR0S7dl3DWtBU6lpOv5tE1lDyhRwX0EOXF3bFH1cC4+y/G3j8x7v6LsfdPjHvFcTXnMQpwG5VuAAAAAHANoRtuycu3Kc92cnIE93QDAAAAQMlITXBLQZVbkkKDuXwAAAAAoCSkJrilcOi28sgwAAAAACgRoRtuyfrf48IkKt0AAAAAUBpSE9ziML2cSjcAAAAAlIjQDbdk5/1b6bZS6QYAAACAEpGa4JasXCrdAAAAAOAqQjfcks093QAAAADgMlIT3JLFPd0AAAAA4DJCN9ziUOkO4vIBAAAAgJKQmuAWh+d0B1PpBgAAAICSELrhliwq3QAAAADgMlIT3EKlGwAAAABcR+iGW7IdFlLj8gEAAACAkpCa4BamlwMAAACA60hNcAvTywEAAADAdYRuuIVHhgEAAACA60hNcIvDPd1UugEAAACgRIRuuCU7799KtzWYywcAAAAASkJqgluycguvXk6lGwAAAABKQuiGW6h0AwAAAIDrSE1wSzaVbgAAAABwGaEbbsnKY/VyAAAAAHAVqQlucax0c/kAAAAAQElITXBLQaU7KMCioEAuHwAAAAAoCakJbimodFPlBgAAAIDSkZzgluy8k6HbGswiagAAAABQGkI33JKVe3J6OZVuAAAAACgdyQluodINAAAAAK4jdMMt2f9bSC2ESjcAAAAAlIrkBJcZY5RVsJAalW4AAAAAKBWhGy7Lyf/3Gd1WKt0AAAAAUCqSE1xWUOWWqHQDAAAAgCsI3XBZwf3cEquXAwAAAIArSE5wWXahSjerlwMAAABA6QjdcBmVbgAAAABwD8kJLstyqHRz6QAAAABAaUhOcFl2XqGF1IKYXg4AAAAApSF0w2XZuUwvBwAAAAB3kJzgssKVbhZSAwAAAIDSEbrhsiwq3QAAAADgFpITXOZ4TzeXDgAAAACUhuQElxV+ZBjTywEAAACgdIRuuKzwI8NCeWQYAAAAAJSK5ASXOVS6eWQYAAAAAJSK0A2XUekGAAAAAPeQnOCywpXuUCrdAAAAAFAqQjdclp1b+DndXDoAAAAAUBqSE1yWRaUbAAAAANxC6IbLCle6eU43AAAAAJSO5ASXZecVnl5OpRsAAAAASkPohsuycgtPL+fSAQAAAIDSkJzgssKV7lAq3QAAAABQKkI3XEalGwAAAADcQ3KCyxwq3YRuAAAAACgVyQkuKwjdoUEBslgsPu4NAAAAAFR+hG64LPt/08upcgMAAACAa0hPcJm90s0iagAAAADgEkI3XJadd7LSbQ3msgEAAAAAV5Ce4LKs3IJ7uql0AwAAAIArCN1wGZVuAAAAAHAP6QkuybcZ5eYbSVS6AQAAAMBVhG64pKDKLbF6OQAAAAC4ivQEl2T/735uSbKyejkAAAAAuITQDZdkUekGAAAAALeRnuASKt0AAAAA4D5CN1ySnfdv6KbSDQAAAACuIT3BJVm5TC8HAAAAAHeRnuCSwpVuppcDAAAAgGsI3XAJlW4AAAAAcB/pCS5xuKebSjcAAAAAuITQDZdk88gwAAAAAHAb6Qkuycql0g0AAAAA7iJ0wyWFK91WKt0AAAAA4BLSE1xCpRsAAAAA3Efohku4pxsAAAAA3Ed6gkuyc3lONwAAAAC4i9ANl2RR6QYAAAAAt5Ge4JLClW5CNwAAAAC4hvQEl2TnMb0cAAAAANxF6IZLsnOZXg4AAAAA7jpt09Pll1+uhg0bymq1KjY2VjfddJP27t3r0OaXX37R+eefL6vVqri4OM2ZM8fpPG+//bZatmwpq9Wqtm3b6pNPPnHYb4zRtGnTFBsbq7CwMPXu3Vtbt24t1/dWGVHpBgAAAAD3BbnTuFevXm6/gMVi0apVq9w+rjQ9e/bU5MmTFRsbqz179uiuu+7S1VdfrW+//VaSlJGRoYsvvli9e/fWwoUL9euvv+qWW25RrVq1NHz4cEnSt99+q4EDB2rWrFm67LLL9Prrr2vAgAFat26d2rRpI0maM2eOHn/8cb388suKj4/X/fffr6SkJP3222+yWq1ef1+VVRaVbgAAAABwm1uh22azyWKxOGz7888/tX37dkVERKhJkyaSpB07dujIkSNq2rSp4uLivNfbQsaPH2//d6NGjXTvvfdqwIABys3NVXBwsJYsWaKcnBy99NJLCgkJ0VlnnaXU1FTNmzfPHroXLFigPn366O6775YkPfjgg0pOTtaTTz6phQsXyhij+fPna+rUqerfv78k6ZVXXlG9evW0bNkyXX/99eXy3iqjwpXuUCrdAAAAAOASt0L3mjVrHD7++uuvdfnll+v555/X4MGDFRR08nR5eXlatGiRJk2apMWLF3urr8U6dOiQlixZovPOO0/BwcGSpJSUFHXv3l0hISH2dklJSZo9e7YOHz6syMhIpaSkaMKECQ7nSkpK0rJlyySd/OVBWlqaevfubd8fERGhhIQEpaSkFBu6s7OzlZ2dbf84IyND0slfWthstiKP8SWbzSZjTIl9K1zpDglQpXwfcJ8rY4+qh3H3X4y9f2Lc/Rdj758Y94rj6ufYrdB9qrvuuktDhw7VsGHDHE8aFKTbbrtNmzdv1oQJE7R27VpPXqZYkyZN0pNPPqnjx4/r3HPP1UcffWTfl5aWpvj4eIf29erVs++LjIxUWlqafVvhNmlpafZ2hY8rqk1RZs2apZkzZzptP3jwoLKystx4hxXDZrMpPT1dxhgFBBQ9dfzoiZO/RAi0SIf++bsiu4dy5MrYo+ph3P0XY++fGHf/xdj7J8a94mRmZrrUzqPQ/csvv+imm24qdn98fLyeeeYZl8937733avbs2SW22bRpk1q2bClJuvvuuzVs2DDt2rVLM2fO1M0336yPPvrIaQp8RbvvvvscKugZGRmKi4tTVFSUwsPDfdizohXcNhAVFVXsF6ZNWySdnFoeHR1dkd1DOXJl7FH1MO7+i7H3T4y7/2Ls/RPjXnFcXePLo9Bdv359LV26VCNGjLBPLS+Ql5enpUuXqn79+i6fb+LEiRoyZEiJbQruG5ekunXrqm7dujrzzDPVqlUrxcXF6bvvvlNiYqJiYmK0f/9+h2MLPo6JibH/XVSbwvsLtsXGxjq06dChQ7F9DA0NVWhoqNP2gICASnvhWyyWEvuXnX9y6oQ1OLDSvgeUTWljj6qJcfdfjL1/Ytz9F2Pvnxj3iuHq59ej0H3PPfdo5MiROvfcczVy5Eg1a9ZMkrR161YtXLhQqampevrpp10+X1RUlKKiosrUl4L59AX3UicmJmrKlCn2hdUkKTk5WS1atFBkZKS9zapVqzRu3Dj7eZKTk5WYmCjpZKU+JiZGq1atsofsjIwMrV27VqNGjSpTP09XBfd0s3I5AAAAALjOo9A9fPhwBQYGasqUKRo+fLh9WrcxRlFRUVq4cKFuu+02r3S0sLVr1+qHH35Qt27dFBkZqT/++EP333+/mjZtag/MgwYN0syZMzVs2DBNmjRJGzZs0IIFC/Sf//zHfp4777xTPXr00Ny5c9W3b1+9+eab+vHHH/Xcc89JOvkbonHjxumhhx5S8+bN7Y8Mq1+/vgYMGOD191WZFaxezjO6AQAAAMB1HoVuSRo2bJgGDx6sH3/8Ubt27ZJ08hFeXbp0cZpy7i3VqlXTe++9p+nTp+vYsWOKjY1Vnz59NHXqVPu07oiICK1cuVKjR49W586dVbduXU2bNs3+uDBJOu+88/T6669r6tSpmjx5spo3b65ly5bZn9EtnazmHzt2TMOHD9eRI0fUrVs3rVixwq+e0S1R6QYAAACAsrAYY4yvO1HVZWRkKCIiQunp6ZV2IbUDBw4oOjq6yPsSjDFqMvkTGSO1bxChD8Z080EvUR5KG3tUTYy7/2Ls/RPj7r8Ye//EuFccV3Oex6Xo/Px8vfbaa/r4448dKt2XXXaZbrjhBgUGMh35dJebb1Twq5lQppcDAAAAgMs8+tVHenq6unbtqltuuUUrV65Ubm6ucnNzlZycrKFDh6pbt27KyMjwVl/hI1l5+fZ/M70cAAAAAFznUYKaMmWKfvrpJz3xxBM6ePCg1q1bp3Xr1unAgQN68skn9eOPP2rKlCne6it8JDvXZv93aBCVbgAAAABwlUeh+/3339ftt9+u22+/3f5YLkkKDg7WqFGjNGrUKL377rsedxK+lV2o0m0NptINAAAAAK7yKEH9888/atGiRbH7W7ZsqUOHDnnyEqgEsqh0AwAAAECZeBS6mzVrpg8//LDY/R9++KGaNm3qyUugEqDSDQAAAABl41GCuv3227Vy5UpdeumlWrlypXbu3KmdO3fqs88+U9++fZWcnKwxY8Z4q6/wESrdAAAAAFA2Hj0y7Pbbb9eBAwf0yCOP6LPPPnPYFxwcrGnTpmnUqFEedRC+V7jSHUqlGwAAAABc5vFzumfMmKExY8YoOTlZu3fvlnTyOd29e/dW3bp1Pe4gfC87799Kt5VKNwAAAAC4zOPQLUl169bVwIEDvXEqVELZuVS6AQAAAKAsvBK6v/jiC3388cfatWuXpJOV7r59+6pHjx7eOD18rHClOzSI0A0AAAAArvIodOfk5GjgwIFatmyZjDGqVauWJOnIkSOaO3eurrjiCr3xxhsOz/DG6Scrt/Dq5UwvBwAAAABXeVS2nDlzpt5//31NnDhR+/bt06FDh3To0CGlpaXprrvu0nvvvacHHnjAW32Fj1DpBgAAAICy8ShBvf766xo8eLDmzJmjevXq2bdHR0dr9uzZuvnmm/Xqq6963En4VnahR4ZR6QYAAAAA13kUuvft26eEhIRi9yckJCgtLc2Tl0AlUHh6OZVuAAAAAHCdRwmqQYMGWrNmTbH7v/jiCzVo0MCTl0Al4Di9nEo3AAAAALjKo9A9ePBgvfXWWxo5cqS2bNmi/Px82Ww2bdmyRaNGjdLbb7+tIUOGeKmr8JXsvMILqVHpBgAAAABXebR6+eTJk/XHH3/oueee0/PPP6+AgJOBzGazyRijwYMHa/LkyV7pKHwnK5dKNwAAAACUhUehOzAwUIsXL9aECRP0ySefODyn+9JLL1W7du280kn4VuFKdyiVbgAAAABwmUehu0C7du0I2FVY4Uq3lUo3AAAAALjMK6Fbko4eParDhw/LGOO0r2HDht56GfgAlW4AAAAAKBuPQndWVpZmzpypF198Uf/880+x7fLz84vdh8qv8OrlVLoBAAAAwHUehe7bb79dL7/8sgYMGKDzzz9fkZGR3uoXKhGH53RT6QYAAAAAl3kUut977z3deuutevbZZ73VH1RChSvdIYGEbgAAAABwlUcJymKxqFOnTt7qCyqp7P8tpBYSFKCAAIuPewMAAAAApw+PQnf//v313//+11t9QSWV9b+F1EKDqHIDAAAAgDvcml5+6NAhh4/vv/9+XXvttRo+fLhGjBihhg0bKjDQeaGt2rVre9ZL+FRBpTuURdQAAAAAwC1uhe66devKYnGcXmyM0fr16/Xiiy8Wexyrl5/eCh4ZZmURNQAAAABwi1uhe9q0aU6hG1Xfv5VuQjcAAAAAuMOt0D1jxoxy6gYqs4LVy63BTC8HAAAAAHdQukSJ8m1GOflUugEAAACgLNyqdD/wwAOyWCyaMmWKAgIC9MADD5R6jMVi0f3331/mDsK3cgo9o5uF1AAAAADAPW5PL7dYLJo0aZJCQkJcmm5O6D69FSyiJrGQGgAAAAC4y63QbbPZSvwYVU9WLpVuAAAAACgrSpcoEZVuAAAAACg7UhRKRKUbAAAAAMrOrenl8fHxbj+n22Kx6I8//nDrGFQehSvdoVS6AQAAAMAtboXuHj16uB26cXrLLrR6Oc/pBgAAAAD3uBW6Fy9eXE7dQGWVlVuo0s1zugEAAADALaQolCjb4Z5uLhcAAAAAcIfHKSojI0OPPPKIkpKS1LFjR33//feSpEOHDmnevHnatm2bx52E72Q5rF7O9HIAAAAAcIdb08tP9ddff6lHjx76888/1bx5c23evFlHjx6VJNWuXVvPPvusdu3apQULFnils6h4VLoBAAAAoOw8Ct133323MjMzlZqaqujoaEVHRzvsHzBggD766COPOgjfKryQWiiVbgAAAABwi0ely5UrV2rs2LFq3bp1kauaN2nSRH/++acnLwEfYyE1AAAAACg7j1LUiRMnFBUVVez+zMxMT06PSsCh0h1EpRsAAAAA3OFR6G7durW+/PLLYvcvW7ZMHTt29OQl4GPZDgupUekGAAAAAHd4lKLGjRunN998U7Nnz1Z6erokyWazadu2bbrpppuUkpKi8ePHe6Wj8I2sXCrdAAAAAFBWHi2kduONN2rXrl2aOnWqpkyZIknq06ePjDEKCAjQww8/rAEDBnijn/CRwpXuUCrdAAAAAOAWj0K3JE2ZMkU33XST3n33XW3btk02m01NmzbVlVdeqSZNmnijj/ChwpVuK5VuAAAAAHCLR6F72bJlGjBggBo2bFjsNPJJkyZp9uzZnrwMfIhKNwAAAACUnUcp6vrrr9eKFSuK3T9y5Eg99thjnrwEfKzw6uVWntMNAAAAAG7xKHTffPPNuvLKK7Vq1SqH7TabTYMGDdLzzz+vp556yqMOwreyeU43AAAAAJSZR9PLn3vuOWVnZ6t///769NNPdf755ysnJ0fXXHONPv30U73yyiu64YYbvNVX+IDjc7oJ3QAAAADgDo8XUlu0aJGys7PVt29fvfPOO5ozZ46++eYbvf322+rfv783+ggfys5lejkAAAAAlJXHoTsgIEBLlizR1VdfrUsuuUTVq1fXxx9/rF69enmjf/CxrP8tpBZgkYICLD7uDQAAAACcXtwK3fPmzSt2X0JCglatWqU+ffooNTVVqampkiSLxVLsyuao/Aoq3aFBgbJYCN0AAAAA4A63Qvddd91Vapt33nlH77zzjv1jQvfpraDSbeVxYQAAAADgNrdC944dO8qrH6ikCle6AQAAAADucSt0N2rUqLz6gUoqm0o3AAAAAJQZSQolyqLSDQAAAABl5lalOz4+XgEBAdq8ebOCg4MVHx9f6uJaFotFf/zxh0edhG8YY+yV7lAq3QAAAADgNrdCd48ePWSxWBQQEODwMaqmPJuRzZz8t5VKNwAAAAC4za3QvXjx4hI/RtWSlZtv/zeVbgAAAABwX7kmqU8++UTDhw8vz5dAOcrOs9n/HRpE6AYAAAAAd5Vrklq/fr1efPHF8nwJlCPHSjfTywEAAADAXZQvUSwq3QAAAADgGZIUipWd+2/otlLpBgAAAAC3EbpRrKy8QtPLqXQDAAAAgNtIUihW4Up3KI8MAwAAAAC3ufXIMEm6/PLLXW67bds2d0+PSiS7UKXbyiPDAAAAAMBtbofuX375RRaLxeX2DRs2dPclUElkUekGAAAAAI+4Hbp37txZDt1AZZTNPd0AAAAA4BGSFIrF6uUAAAAA4Bmvhu7Dhw+rV69eWr9+vTdPCx+h0g0AAAAAnvFqksrJydGaNWt0+PBhb54WPpKdR6UbAAAAADxB+RLFysql0g0AAAAAniBJoViFK92hPDIMAAAAANzm1SQVFhamwYMHq379+t48LXykcKWb6eUAAAAA4D63HxlWkvDwcC1atMibp4QPOVS6mV4OAAAAAG7zKHTv3r27xP0Wi0VWq1V169aVxWLx5KXgA4UfGRYaRKUbAAAAANzlUehu3LixS2HaarXq/PPP1/3336+uXbt68pKoQFl5haeXU+kGAAAAAHd5FLpffPFFPf744/rzzz91ww03qFmzZpKkrVu36vXXX1ejRo00dOhQbdu2Ta+99pp69eqlFStWqGfPnl7pPMoXlW4AAAAA8IxH5cu9e/cqJydH27Zt04IFC3THHXfojjvu0OOPP67ff/9dJ06c0IkTJzR//nxt2bJFsbGxmjlzprf6LknKzs5Whw4dZLFYlJqa6rDvl19+0fnnny+r1aq4uDjNmTPH6fi3335bLVu2lNVqVdu2bfXJJ5847DfGaNq0aYqNjVVYWJh69+6trVu3evU9VFbZVLoBAAAAwCMeJamFCxfq1ltvVa1atZz21a5dW7feequefPJJSVKdOnV0yy236KeffvLkJZ3cc889Ra6WnpGRoYsvvliNGjXSTz/9pEcffVQzZszQc889Z2/z7bffauDAgRo2bJjWr1+vAQMGaMCAAdqwYYO9zZw5c/T4449r4cKFWrt2rapXr66kpCRlZWV59X1URllUugEAAADAIx6F7n/++UfHjx8vdv+xY8d08OBB+8cxMTEyxnjykg4+/fRTrVy5Uo899pjTviVLlignJ0cvvfSSzjrrLF1//fUaO3as5s2bZ2+zYMEC9enTR3fffbdatWqlBx98UJ06dbL/osAYo/nz52vq1Knq37+/2rVrp1deeUV79+7VsmXLvPY+KqvClW5WLwcAAAAA93l0T/fZZ5+tBQsW6PLLL1fbtm0d9v3yyy964okndM4559i3bdq0SQ0aNPDkJe3279+v2267TcuWLVO1atWc9qekpKh79+4KCQmxb0tKStLs2bN1+PBhRUZGKiUlRRMmTHA4LikpyR6od+zYobS0NPXu3du+PyIiQgkJCUpJSdH1119fZN+ys7OVnZ1t/zgjI0OSZLPZZLPZijzGl2w2m4wxTn0reE53SKBFkpHN5r1fmKByKG7sUbUx7v6LsfdPjLv/Yuz9E+NecVz9HHsUup944gn17NlTHTt2VGJion0htW3btiklJUXh4eF6/PHHJUlZWVlas2aNrr76ak9eUtLJCvSQIUM0cuRIdenSRTt37nRqk5aWpvj4eIdt9erVs++LjIxUWlqafVvhNmlpafZ2hY8rqk1RZs2aVeS96wcPHqyU09JtNpvS09NljFFAwL8V7WNZuZKk4ECLDhw44KvuoRwVN/ao2hh3/8XY+yfG3X8x9v6Jca84mZmZLrXzKHS3a9dOv/76qx555BF99tln+uGHHyRJjRo10u2336577rnHXtm2Wq1av359iee79957NXv27BLbbNq0SStXrlRmZqbuu+8+T7pfbu677z6HCnpGRobi4uIUFRWl8PBwH/asaDabTRaLRVFRUQ5fmPn6TZIUFhKk6OhoX3UP5ai4sUfVxrj7L8bePzHu/oux90+Me8WxWq0utfModEtS/fr17dVsT02cOFFDhgwpsU2TJk30+eefKyUlRaGhoQ77unTpohtuuEEvv/yyYmJitH//fof9BR/HxMTY/y6qTeH9BdtiY2Md2nTo0KHYPoaGhjr1TZICAgIq7YVvsVic+lewkFpoUGCl7Tc8V9TYo+pj3P0XY++fGHf/xdj7J8a9Yrj6+fU4dBc4evSo/vzzT0lSXFycatSo4fY5oqKiFBUVVWq7xx9/XA899JD947179yopKUlLly5VQkKCJCkxMVFTpkxRbm6ugoODJUnJyclq0aKFIiMj7W1WrVqlcePG2c+VnJysxMRESVJ8fLxiYmK0atUqe8jOyMjQ2rVrNWrUKLff3+mmYCG1UB4XBgAAAABl4nGa+uGHH9SzZ09FRkaqTZs2atOmjSIjI9WrVy/9+OOP3uijk4YNG9pfq02bNjrzzDMlSU2bNrVPZx80aJBCQkI0bNgwbdy4UUuXLtWCBQscpn3feeedWrFihebOnavNmzdrxowZ+vHHHzVmzBhJJ39DNG7cOD300EP68MMP9euvv+rmm29W/fr1NWDAgHJ5b5VJdt7JSreVx4UBAAAAQJl4VOleu3atLrjgAoWEhOjWW29Vq1atJJ287/qNN95Q9+7dtWbNGocVzCtKRESEVq5cqdGjR6tz586qW7eupk2bpuHDh9vbnHfeeXr99dc1depUTZ48Wc2bN9eyZcvUpk0be5t77rlHx44d0/Dhw3XkyBF169ZNK1ascHn+/unKZjPK+V/optINAAAAAGVjMR48OLt3797auXOnvv76a/v9zwX279+vrl27Kj4+XsnJyR539HSWkZGhiIgIpaenV9qF1A4cOKDo6Gj7fQlZuflqef8KSdK5TWrrzeGJvuwiyklRY4+qj3H3X4y9f2Lc/Rdj758Y94rjas7zaBTWrl2rESNGOAVu6eRjtYYPH67vvvvOk5eAjxQ8o1uSrMFMLwcAAACAsvAodAcEBCgvL6/Y/fn5+fx25TRVcD+3JIUGMYYAAAAAUBYepanzzjtPTz31lHbt2uW0b/fu3Xr66afVtWtXT14CPpKd+2/optINAAAAAGXj0UJqDz/8sLp3766WLVvqiiuusK8ivmXLFn3wwQcKDAzUrFmzvNJRVKysvH+nl1PpBgAAAICy8Sh0d+zYUWvXrtWUKVP04Ycf6vjx45KkatWqqU+fPpoxY4bq1q3rlY6iYhWudIfyyDAAAAAAKBOPS5itW7fW+++/r4yMDO3bt0/79u1TRkaG3nvvPS1fvlxxcXHe6CcqWHZe4YXUqHQDAAAAQFl4VOkuLCAgQPXq1fPW6eBjWVS6AQAAAMBjlDBRpGzu6QYAAAAAj5GmUKQsVi8HAAAAAI8RulEkh0o393QDAAAAQJm4fU/3unXrXG67d+9ed0+PSiI7r1Clm3u6AQAAAKBM3A7dXbp0kcVicamtMcbltqhcsnKpdAMAAACAp9wO3YsWLSqPfqCSKVzpZiE1AAAAACgbt0P34MGDy6MfqGQcK91MLwcAAACAsqCEiSJR6QYAAAAAz5GmUKTs3MKhm0o3AAAAAJQFoRtFyir0yDArC6kBAAAAQJmQplAkKt0AAAAA4DlCN4qUTaUbAAAAADxGmkKRsqh0AwAAAIDHCN0oUuFKdyiVbgAAAAAoE9IUilT4nm4rlW4AAAAAKBNCN4pUUOm2WKTgQIuPewMAAAAApydCN4qUnXey0h0aFCCLhdANAAAAAGVB6EaRsnJPVrqtwUwtBwAAAICyInSjSIUr3QAAAACAsiFRoUgFoZtKNwAAAACUHaEbRSqYXk6lGwAAAADKjkSFIv07vZxKNwAAAACUFaEbTnLzbcq3GUmSNZhLBAAAAADKikQFJwVVbolKNwAAAAB4gtANJ9n/u59b4p5uAAAAAPAEiQpOsgpVulm9HAAAAADKjtANJ1S6AQAAAMA7SFRw4nBPN5VuAAAAACgzQjecZFHpBgAAAACvIFHBiWOlm0sEAAAAAMqKRAUnhSvdVh4ZBgAAAABlRuiGEyrdAAAAAOAdJCo4cQjdVLoBAAAAoMwI3XDiML2cSjcAAAAAlBmJCk6odAMAAACAdxC64SSbSjcAAAAAeAWJCk6odAMAAACAdxC64aRwpTs0iEsEAAAAAMqKRAUnWYUq3dZgKt0AAAAAUFaEbjih0g0AAAAA3kGigpNsKt0AAAAA4BWEbjjJotINAAAAAF5BooITh9XLeWQYAAAAAJQZiQpOCle6rTwyDAAAAADKjNANJ1S6AQAAAMA7SFRw4hC6qXQDAAAAQJkRuuGkYHp5cKBFgQEWH/cGAAAAAE5fhG44Kah0U+UGAAAAAM8QuuEkO+9kpdvK/dwAAAAA4BFSFZxk5VLpBgAAAABvIHTDSfb/7ukODeLyAAAAAABPkKrgJKvgnu5gKt0AAAAA4AlCNxwYY5RjX0iNywMAAAAAPEGqggPHZ3RzeQAAAACAJ0hVcJCd+2/otjK9HAAAAAA8QuiGg4LHhUlUugEAAADAU6QqOCg8vZxKNwAAAAB4htANB1m5VLoBAAAAwFtIVXDgsJBaMJcHAAAAAHiCVAUHhSvd1iCmlwMAAACAJwjdcEClGwAAAAC8h1QFB46rl1PpBgAAAABPELrhIMvhOd1cHgAAAADgCVIVHFDpBgAAAADvIXTDQTaVbgAAAADwGlIVHDg+p5tKNwAAAAB4gtANBw6rlwdxeQAAAACAJ0hVcOC4kBqVbgAAAADwBKEbDhwXUuPyAAAAAABPkKrgwGF6OQupAQAAAIBHSFVwwEJqAAAAAOA9hG44KFzp5pFhAAAAAOAZUhUcUOkGAAAAAO8hdMMB93QDAAAAgPeQquDA8TndVLoBAAAAwBOnbehu3LixLBaLw59HHnnEoc0vv/yi888/X1arVXFxcZozZ47Ted5++221bNlSVqtVbdu21SeffOKw3xijadOmKTY2VmFhYerdu7e2bt1aru/NlwpPL+eebgAAAADwzGmdqh544AHt27fP/ueOO+6w78vIyNDFF1+sRo0a6aefftKjjz6qGTNm6LnnnrO3+fbbbzVw4EANGzZM69ev14ABAzRgwABt2LDB3mbOnDl6/PHHtXDhQq1du1bVq1dXUlKSsrKyKvS9VpTCle6QwNP68gAAAAAAnzutU1XNmjUVExNj/1O9enX7viVLlignJ0cvvfSSzjrrLF1//fUaO3as5s2bZ2+zYMEC9enTR3fffbdatWqlBx98UJ06ddKTTz4p6WSVe/78+Zo6dar69++vdu3a6ZVXXtHevXu1bNmyin67FSL7f5Xu0KAAWSwWH/cGAAAAAE5vQb7ugCceeeQRPfjgg2rYsKEGDRqk8ePHKyjo5FtKSUlR9+7dFRISYm+flJSk2bNn6/Dhw4qMjFRKSoomTJjgcM6kpCR7oN6xY4fS0tLUu3dv+/6IiAglJCQoJSVF119/fZH9ys7OVnZ2tv3jjIwMSZLNZpPNZivyGF+y2Wwyxshms9mnl1uDAytlX+Fdhcce/oNx91+MvX9i3P0XY++fGPeK4+rn+LQN3WPHjlWnTp1Uu3Ztffvtt7rvvvu0b98+eyU7LS1N8fHxDsfUq1fPvi8yMlJpaWn2bYXbpKWl2dsVPq6oNkWZNWuWZs6c6bT94MGDlXJaus1mU3p6uowxOpGTK0kKDpAOHDjg456hvBUe+4CA03riC9zAuPsvxt4/Me7+i7H3T4x7xcnMzHSpXaUK3ffee69mz55dYptNmzapZcuWDhXqdu3aKSQkRCNGjNCsWbMUGhpa3l0t0X333efQv4yMDMXFxSkqKkrh4eE+7FnRbDabLBaLoqKiVLCOWrXQIEVHR/u2Yyh3hceeb8r+g3H3X4y9f2Lc/Rdj758Y94pjtVpdalepQvfEiRM1ZMiQEts0adKkyO0JCQnKy8vTzp071aJFC8XExGj//v0ObQo+jomJsf9dVJvC+wu2xcbGOrTp0KFDsX0MDQ0tMvgHBARU2gvfYrEoICDAvpBaaFBgpe0rvKtg7Blv/8K4+y/G3j8x7v6LsfdPjHvFcPXzW6lCd1RUlKKiosp0bGpqqgICAuzV2cTERE2ZMkW5ubkKDg6WJCUnJ6tFixaKjIy0t1m1apXGjRtnP09ycrISExMlSfHx8YqJidGqVavsITsjI0Nr167VqFGjyvguKzd76OZxYQAAAADgsdMyWaWkpGj+/Pn6+eeftX37di1ZskTjx4/XjTfeaA/UgwYNUkhIiIYNG6aNGzdq6dKlWrBggcO07zvvvFMrVqzQ3LlztXnzZs2YMUM//vijxowZI+nkb4jGjRunhx56SB9++KF+/fVX3Xzzzapfv74GDBjgi7dervLybcqzGUmSNSjQx70BAAAAgNNfpap0uyo0NFRvvvmmZsyYoezsbMXHx2v8+PEOgToiIkIrV67U6NGj1blzZ9WtW1fTpk3T8OHD7W3OO+88vf7665o6daomT56s5s2ba9myZWrTpo29zT333KNjx45p+PDhOnLkiLp166YVK1a4PH//dFL4Gd1UugEAAADAc6dl6O7UqZO+++67Utu1a9dOX331VYltrrnmGl1zzTXF7rdYLHrggQf0wAMPuN3P041D6KbSDQAAAAAeo5wJu4JndEuSlUo3AAAAAHiMZAU7Kt0AAAAA4F2EbthR6QYAAAAA7yJZwS6HSjcAAAAAeBWhG3aO08u5NAAAAADAUyQr2BWeXh4aTKUbAAAAADxF6IYdlW4AAAAA8C6SFewI3QAAAADgXSQr2DmuXs70cgAAAADwFKEbdlS6AQAAAMC7SFawo9INAAAAAN5F6IYdlW4AAAAA8C6SFewcQjeVbgAAAADwGKEbdtmFp5dT6QYAAAAAj5GsYEelGwAAAAC8i9ANO8eF1Lg0AAAAAMBTJCvYOS6kRqUbAAAAADxF6IYdq5cDAAAAgHeRrGDHc7oBAAAAwLsI3bCj0g0AAAAA3kWygh2hGwAAAAC8i2QFu4LndAcFWBQUyKUBAAAAAJ4iWcGuoNJNlRsAAAAAvIN0BbuChdRYRA0AAAAAvIPQDTsq3QAAAADgXaQr2NlDN5VuAAAAAPAKQjfsCqaXU+kGAAAAAO8gXUGSZIyh0g0AAAAAXkbohiQpN9/Y/02lGwAAAAC8g3QFSf/ezy2xejkAAAAAeAuhG5KkHCrdAAAAAOB1pCtIotINAAAAAOWB0A1JUnb+v6GbSjcAAAAAeAfpCpKknDymlwMAAACAt5GuIInp5QAAAABQHgjdkCTlML0cAAAAALyOdAVJp04vp9INAAAAAN5A6IYkKcthejmXBQAAAAB4A+kKkpheDgAAAADlgXQFSVJ2oenlLKQGAAAAAN5B6IYkKafQ9PJQppcDAAAAgFeQriDp1OnlVLoBAAAAwBsI3ZB06vRyLgsAAAAA8AbSFSRJ2XlUugEAAADA2wjdkHRq6OayAAAAAABvIF1BkpSTz+rlAAAAAOBthG5IOmX1cirdAAAAAOAVpCtIcpxeTqUbAAAAALyD0A1JjtPLqXQDAAAAgHeQriCJ1csBAAAAoDwQuiHplNDNc7oBAAAAwCtIV5DE9HIAAAAAKA+kK0j6t9IdEhQgi8Xi494AAAAAQNVA6IYkKSf/ZOi2UuUGAAAAAK8hYUGSlJN3cnp5KI8LAwAAAACvIXRD0r/Ty60sogYAAAAAXkPCgiQp+3/Ty3lcGAAAAAB4D6EbkgpNL+eebgAAAADwGhIWlG8zyrOdDN1W7ukGAAAAAK8hdEPZefn2f1PpBgAAAADvIWFBWbk2+78J3QAAAADgPSQsOFS6mV4OAAAAAN5D6Ib9cWESlW4AAAAA8CYSFhyml1PpBgAAAADvIXSDhdQAAAAAoJyQsKDswgupUekGAAAAAK8hdMNxITUq3QAAAADgNSQsOC6kRqUbAAAAALyG0A2e0w0AAAAA5YSEBceF1Kh0AwAAAIDXELrhuJAalW4AAAAA8BoSFpRVeCE1Kt0AAAAA4DWEbjgupEalGwAAAAC8hoQFppcDAAAAQDkhYYHp5QAAAABQTgjdUA6VbgAAAAAoFyQsKKvQPd1UugEAAADAewjdcHxON5VuAAAAAPAaEhYcF1Kj0g0AAAAAXkPohuNCalS6AQAAAMBrSFhwfE43lW4AAAAA8BpCt5/LtxkdzMy2fxwUYPFhbwAAAACgajmtQ/fHH3+shIQEhYWFKTIyUgMGDHDYv3v3bvXt21fVqlVTdHS07r77buXl5Tm0WbNmjTp16qTQ0FA1a9ZMixcvdnqdp556So0bN5bValVCQoK+//77cnxXFWfFhn3qNvtz/b7/qH1bz8fWaMWGfT7sFQAAAABUHadt6H733Xd10003aejQofr555/1zTffaNCgQfb9+fn56tu3r3JycvTtt9/q5Zdf1uLFizVt2jR7mx07dqhv377q2bOnUlNTNW7cON1666367LPP7G2WLl2qCRMmaPr06Vq3bp3at2+vpKQkHThwoELfr7et2LBPo15bp33pWQ7b09KzNOq1dQRvAAAAAPACizHG+LoT7srLy1Pjxo01c+ZMDRs2rMg2n376qS677DLt3btX9erVkyQtXLhQkyZN0sGDBxUSEqJJkybp448/1oYNG+zHXX/99Tpy5IhWrFghSUpISNDZZ5+tJ598UpJks9kUFxenO+64Q/fee69L/c3IyFBERITS09MVHh7uyVv3inybUbfZnzsF7gIWSTERVn09qZcCmW5epdlsNh04cEDR0dEKCDhtfwcHNzHu/oux90+Mu/9i7P0T415xXM15QRXYJ69Zt26d9uzZo4CAAHXs2FFpaWnq0KGDHn30UbVp00aSlJKSorZt29oDtyQlJSVp1KhR2rhxozp27KiUlBT17t3b4dxJSUkaN26cJCknJ0c//fST7rvvPvv+gIAA9e7dWykpKcX2Lzs7W9nZ/94nnZGRIenkF4DNZivusAqzdvs/xQZuSTKS9qVnae32v3VukzoV1zFUOJvNJmNMpbguUXEYd//F2Psnxt1/Mfb+iXGvOK5+jk/L0L19+3ZJ0owZMzRv3jw1btxYc+fO1QUXXKDff/9dtWvXVlpamkPglmT/OC0tzf53UW0yMjJ04sQJHT58WPn5+UW22bx5c7H9mzVrlmbOnOm0/eDBg8rKKj7sVpRtfx1ysd1BNamRX3pDnLZsNpvS09NljOE3oX6EcfdfjL1/Ytz9F2Pvnxj3ipOZmelSu0oVuu+9917Nnj27xDabNm2y/0ZhypQpuuqqqyRJixYtUoMGDfT2229rxIgR5d7Xktx3332aMGGC/eOMjAzFxcUpKiqqUkwvb3Y0UNKO0ts1iFJ0NJXuqsxms8lisSgqKopvyn6EcfdfjL1/Ytz9F2Pvnxj3imO1Wl1qV6lC98SJEzVkyJAS2zRp0kT79p1c5Kt169b27aGhoWrSpIl2794tSYqJiXFaZXz//v32fQV/F2wr3CY8PFxhYWEKDAxUYGBgkW0KzlGU0NBQhYaGOm0PCAioFBd+QpO6io2wKi09S0Xd0F9wT3dCk7oK4J7uKs9isVSaaxMVh3H3X4y9f2Lc/Rdj758Y94rh6ue3Uo1CVFSUWrZsWeKfkJAQde7cWaGhodqyZYv92NzcXO3cuVONGjWSJCUmJurXX391WGU8OTlZ4eHh9rCemJioVatWOfQhOTlZiYmJkmR/rcJtbDabVq1aZW9zOgoMsGh6v5Ofg1MjdcHH0/u1ZhE1AAAAAPBQpQrdrgoPD9fIkSM1ffp0rVy5Ulu2bNGoUaMkSddcc40k6eKLL1br1q1100036eeff9Znn32mqVOnavTo0fYq9MiRI7V9+3bdc8892rx5s55++mm99dZbGj9+vP21JkyYoOeff14vv/yyNm3apFGjRunYsWMaOnRoxb9xL+rTJlbP3NhJMRGOUyJiIqx65sZO6tMm1kc9AwAAAICqo1JNL3fHo48+qqCgIN100006ceKEEhIS9PnnnysyMlKSFBgYqI8++kijRo1SYmKiqlevrsGDB+uBBx6wnyM+Pl4ff/yxxo8frwULFqhBgwZ64YUXlJSUZG9z3XXX6eDBg5o2bZp9lfQVK1Y4La52OurTJlYXtY7R2u1/a9tfB9WsQZQSmtSlwg0AAAAAXnJaPqf7dFPZntN9Kp7l578Ye//EuPsvxt4/Me7+i7H3T4x7xXE15zEKAAAAAACUE0I3AAAAAADlhNANAAAAAEA5IXQDAAAAAFBOCN0AAAAAAJQTQjcAAAAAAOWE0A0AAAAAQDkhdAMAAAAAUE4I3QAAAAAAlBNCNwAAAAAA5YTQDQAAAABAOSF0AwAAAABQTgjdAAAAAACUE0I3AAAAAADlhNANAAAAAEA5CfJ1B/yBMUaSlJGR4eOeFM1msykzM1NWq1UBAfwexp8w9v6JcfdfjL1/Ytz9F2Pvnxj3ilOQ7wryXnEI3RUgMzNTkhQXF+fjngAAAAAAvCkzM1MRERHF7reY0mI5PGaz2bR3717VrFlTFovF191xkpGRobi4OP35558KDw/3dXdQgRh7/8S4+y/G3j8x7v6LsfdPjHvFMcYoMzNT9evXL3FWAZXuChAQEKAGDRr4uhulCg8P5wvTTzH2/olx91+MvX9i3P0XY++fGPeKUVKFuwCT/AEAAAAAKCeEbgAAAAAAygmhGwoNDdX06dMVGhrq666ggjH2/olx91+MvX9i3P0XY++fGPfKh4XUAAAAAAAoJ1S6AQAAAAAoJ4RuAAAAAADKCaEbAAAAAIByQuiGnnrqKTVu3FhWq1UJCQn6/vvvfd0leNmXX36pfv36qX79+rJYLFq2bJnDfmOMpk2bptjYWIWFhal3797aunWrbzoLr5k1a5bOPvts1axZU9HR0RowYIC2bNni0CYrK0ujR49WnTp1VKNGDV111VXav3+/j3oMb3jmmWfUrl07+/NZExMT9emnn9r3M+b+4ZFHHpHFYtG4cePs2xj7qmnGjBmyWCwOf1q2bGnfz7hXXXv27NGNN96oOnXqKCwsTG3bttWPP/5o38/Pd5UHodvPLV26VBMmTND06dO1bt06tW/fXklJSTpw4ICvuwYvOnbsmNq3b6+nnnqqyP1z5szR448/roULF2rt2rWqXr26kpKSlJWVVcE9hTd98cUXGj16tL777jslJycrNzdXF198sY4dO2ZvM378eC1fvlxvv/22vvjiC+3du1dXXnmlD3sNTzVo0ECPPPKIfvrpJ/3444/q1auX+vfvr40bN0pizP3BDz/8oGeffVbt2rVz2M7YV11nnXWW9u3bZ//z9ddf2/cx7lXT4cOH1bVrVwUHB+vTTz/Vb7/9prlz5yoyMtLehp/vKhEDv3bOOeeY0aNH2z/Oz8839evXN7NmzfJhr1CeJJn333/f/rHNZjMxMTHm0UcftW87cuSICQ0NNW+88YYPeojycuDAASPJfPHFF8aYk+McHBxs3n77bXubTZs2GUkmJSXFV91EOYiMjDQvvPACY+4HMjMzTfPmzU1ycrLp0aOHufPOO40xfL1XZdOnTzft27cvch/jXnVNmjTJdOvWrdj9/HxXuVDp9mM5OTn66aef1Lt3b/u2gIAA9e7dWykpKT7sGSrSjh07lJaW5nAdREREKCEhgeugiklPT5ck1a5dW5L0008/KTc312HsW7ZsqYYNGzL2VUR+fr7efPNNHTt2TImJiYy5Hxg9erT69u3rMMYSX+9V3datW1W/fn01adJEN9xwg3bv3i2Jca/KPvzwQ3Xp0kXXXHONoqOj1bFjRz3//PP2/fx8V7kQuv3Y33//rfz8fNWrV89he7169ZSWluajXqGiFYw110HVZrPZNG7cOHXt2lVt2rSRdHLsQ0JCVKtWLYe2jP3p79dff1WNGjUUGhqqkSNH6v3331fr1q0Z8yruzTff1Lp16zRr1iynfYx91ZWQkKDFixdrxYoVeuaZZ7Rjxw6df/75yszMZNyrsO3bt+uZZ55R8+bN9dlnn2nUqFEaO3asXn75ZUn8fFfZBPm6AwCA8jd69Ght2LDB4T4/VF0tWrRQamqq0tPT9c4772jw4MH64osvfN0tlKM///xTd955p5KTk2W1Wn3dHVSgSy65xP7vdu3aKSEhQY0aNdJbb72lsLAwH/YM5clms6lLly56+OGHJUkdO3bUhg0btHDhQg0ePNjHvcOpqHT7sbp16yowMNBpBcv9+/crJibGR71CRSsYa66DqmvMmDH66KOPtHr1ajVo0MC+PSYmRjk5OTpy5IhDe8b+9BcSEqJmzZqpc+fOmjVrltq3b68FCxYw5lXYTz/9pAMHDqhTp04KCgpSUFCQvvjiCz3++OMKCgpSvXr1GHs/UatWLZ155pnatm0bX/NVWGxsrFq3bu2wrVWrVvZbC/j5rnIhdPuxkJAQde7cWatWrbJvs9lsWrVqlRITE33YM1Sk+Ph4xcTEOFwHGRkZWrt2LdfBac4YozFjxuj999/X559/rvj4eIf9nTt3VnBwsMPYb9myRbt372bsqxibzabs7GzGvAq78MIL9euvvyo1NdX+p0uXLrrhhhvs/2bs/cPRo0f1xx9/KDY2lq/5Kqxr165OjwH9/fff1ahRI0n8fFfZML3cz02YMEGDBw9Wly5ddM4552j+/Pk6duyYhg4d6uuuwYuOHj2qbdu22T/esWOHUlNTVbt2bTVs2FDjxo3TQw89pObNmys+Pl7333+/6tevrwEDBviu0/DY6NGj9frrr+uDDz5QzZo17fdwRUREKCwsTBERERo2bJgmTJig2rVrKzw8XHfccYcSExN17rnn+rj3KKv77rtPl1xyiRo2bKjMzEy9/vrrWrNmjT777DPGvAqrWbOmfb2GAtWrV1edOnXs2xn7qumuu+5Sv3791KhRI+3du1fTp09XYGCgBg4cyNd8FTZ+/Hidd955evjhh3Xttdfq+++/13PPPafnnntOkmSxWPj5rjLx9fLp8L0nnnjCNGzY0ISEhJhzzjnHfPfdd77uErxs9erVRpLTn8GDBxtjTj5W4v777zf16tUzoaGh5sILLzRbtmzxbafhsaLGXJJZtGiRvc2JEyfM7bffbiIjI021atXMFVdcYfbt2+e7TsNjt9xyi2nUqJEJCQkxUVFR5sILLzQrV66072fM/UfhR4YZw9hXVdddd52JjY01ISEh5owzzjDXXXed2bZtm30/4151LV++3LRp08aEhoaali1bmueee85hPz/fVR4WY4zxUd4HAAAAAKBK455uAAAAAADKCaEbAAAAAIByQugGAAAAAKCcELoBAAAAACgnhG4AAAAAAMoJoRsAAAAAgHJC6AYAAAAAoJwQugEAAAAAKCeEbgAA4BNr1qyRxWLRmjVrfN0VAADKDaEbAIAqYvHixbJYLPrxxx8lSZ988olmzJjh205Jevrpp7V48WJfdwMAAJ8gdAMAUEV98sknmjlzpq+7UWzo7t69u06cOKHu3btXfKcAAKgghG4AAOAyY4xOnDjhlXMFBATIarUqIIAfRwAAVRf/ywEAUAUNGTJETz31lCTJYrHY/xSw2WyaP3++zjrrLFmtVtWrV08jRozQ4cOHHc7TuHFjXXbZZfrss8/UpUsXhYWF6dlnn5UkLVq0SL169VJ0dLRCQ0PVunVrPfPMM07Hb9y4UV988YW9DxdccIGk4u/pfvvtt9W5c2eFhYWpbt26uvHGG7Vnzx6n91ejRg3t2bNHAwYMUI0aNRQVFaW77rpL+fn53vgUAgDgFUG+7gAAAPC+ESNGaO/evUpOTtarr75a5P7Fixdr6NChGjt2rHbs2KEnn3xS69ev1zfffKPg4GB72y1btmjgwIEaMWKEbrvtNrVo0UKS9Mwzz+iss87S5ZdfrqCgIC1fvly33367bDabRo8eLUmaP3++7rjjDtWoUUNTpkyRJNWrV6/Yfhf06eyzz9asWbO0f/9+LViwQN98843Wr1+vWrVq2dvm5+crKSlJCQkJeuyxx/Tf//5Xc+fOVdOmTTVq1ChvfBoBAPCcAQAAVcKiRYuMJPPDDz8YY4wZPXq0Keq/+q+++spIMkuWLHHYvmLFCqftjRo1MpLMihUrnM5z/Phxp21JSUmmSZMmDtvOOuss06NHD6e2q1evNpLM6tWrjTHG5OTkmOjoaNOmTRtz4sQJe7uPPvrISDLTpk2zbxs8eLCRZB544AGHc3bs2NF07tzZ6bUAAPAVppcDAOBn3n77bUVEROiiiy7S33//bf/TuXNn1ahRQ6tXr3ZoHx8fr6SkJKfzhIWF2f+dnp6uv//+Wz169ND27duVnp7udr9+/PFHHThwQLfffrusVqt9e9++fdWyZUt9/PHHTseMHDnS4ePzzz9f27dvd/u1AQAoL0wvBwDAz2zdulXp6emKjo4ucv+BAwccPo6Pjy+y3TfffKPp06crJSVFx48fd9iXnp6uiIgIt/q1a9cuSbJPXy+sZcuW+vrrrx22Wa1WRUVFOWyLjIx0ui8dAABfInQDAOBnbDaboqOjtWTJkiL3nxpkC1e0C/zxxx+68MIL1bJlS82bN09xcXEKCQnRJ598ov/85z+y2Wzl0vfCAgMDy/01AADwFKEbAIAqqvBq5YU1bdpU//3vf9W1a9ciA7Urli9fruzsbH344Ydq2LChffupU9NL6sepGjVqJOnkwm29evVy2Ldlyxb7fgAATifc0w0AQBVVvXp1SdKRI0cctl977bXKz8/Xgw8+6HRMXl6eU/uiFFSZjTH2benp6Vq0aFGR/XDlnF26dFF0dLQWLlyo7Oxs+/ZPP/1UmzZtUt++fUs9BwAAlQ2VbgAAqqjOnTtLksaOHaukpCQFBgbq+uuvV48ePTRixAjNmjVLqampuvjiixUcHKytW7fq7bff1oIFC3T11VeXeO6LL75YISEh6tevn0aMGKGjR4/q+eefV3R0tPbt2+fUj2eeeUYPPfSQmjVrpujoaKdKtiQFBwdr9uzZGjp0qHr06KGBAwfaHxnWuHFjjR8/3nufHAAAKgihGwCAKurKK6/UHXfcoTfffFOvvfaajDG6/vrrJUkLFy5U586d9eyzz2ry5MkKCgpS48aNdeONN6pr166lnrtFixZ65513NHXqVN11112KiYnRqFGjFBUVpVtuucWh7bRp07Rr1y7NmTNHmZmZ6tGjR5GhW5KGDBmiatWq6ZFHHtGkSZNUvXp1XXHFFZo9e7bDM7oBADhdWEzheWEAAAAAAMBruKcbAAAAAIByQugGAAAAAKCcELoBAAAAACgnhG4AAAAAAMoJoRsAAAAAgHJC6AYAAAAAoJwQugEAAAAAKCeEbgAAAAAAygmhGwAAAACAckLoBgAAAACgnBC6AQAAAAAoJ4RuAAAAAADKCaEbAAAAAIBy8v/74gTwA8HzRwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Plotted log-likelihood convergence\n",
            "\n",
            "======================================================================\n",
            "TEST 5: Final Model Properties\n",
            "======================================================================\n",
            "\n",
            "Converged: True\n",
            "Number of iterations: 64\n",
            "\n",
            "Final component weights: [0.68958108 0.31041892]\n",
            "\n",
            "Means shape: (2, 30)\n",
            "Component 0 mean (first 5 features): [-0.41152084 -0.20875672 -0.42068568 -0.40175135 -0.22174502]\n",
            "Component 1 mean (first 5 features): [0.91417426 0.46374326 0.93453352 0.8924718  0.49259616]\n",
            "\n",
            "Covariances shape: (2, 30, 30)\n",
            "\n",
            "Component 0 covariance:\n",
            "  Min eigenvalue: 7.985083e-05\n",
            "  Max eigenvalue: 7.560221e+00\n",
            "  Condition number: 94679.30\n",
            "\n",
            "Component 1 covariance:\n",
            "  Min eigenvalue: 2.254649e-04\n",
            "  Max eigenvalue: 9.031683e+00\n",
            "  Condition number: 40058.04\n",
            "\n",
            "======================================================================\n",
            "TEST 6: Comparison with True Labels\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[348   9]\n",
            " [ 53 159]]\n",
            "\n",
            "Adjusted Rand Index: 0.6068\n",
            "Best matching accuracy: 0.8910 (89.10%)\n",
            "\n",
            "======================================================================\n",
            "ALL TESTS COMPLETED SUCCESSFULLY!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ]
}