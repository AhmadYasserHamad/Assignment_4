{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook aims to write the code necessary for all evaluation and analysis metrics. The metrics considred will be:\n",
        "\n",
        "- Silhouette Score\n",
        "\n",
        "- Davies-Bouldin Index\n",
        "\n",
        "- Calinski-Harabasz Index\n",
        "\n",
        "- Adjusted Rand Index\n",
        "\n",
        "- Normalized Mutual Information\n",
        "\n",
        "- Purity"
      ],
      "metadata": {
        "id": "zneK2Ei_vU4_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLyFfnOAvQqv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Silhouette Score\n",
        "# Measuring the accuracy of the cluster. Measure of how good the cluster is formed. Ranges from [-1,1].\n",
        "# Items in a cluster must be coherent (share similar characteristics) and must be easily seperable from items in other clusters.\n",
        "# To measure the silhouette coefficient, you must compute both cohesion and separation. In the end, you have to take the average\n",
        "# of all silhouette scores for each data point to find the silhouette score of clusters.\n",
        "# Aim to find how different clusters are to one another.\n",
        "\n",
        "# Cohesion --> how close the current data point is to its neighboring data points (of the same cluster). Then compute average.\n",
        "# Separation --> how close the current data point is to points in the other clusters. Then compute average.\n",
        "\n",
        "# silhouette coefficient --> (separation - cohesion)/max(separation, cohesion)\n",
        "# The closer to one, the better the cluster generated (perfect clusters generated). Therefore, separation should be large, cohesion should be small.\n",
        "\n",
        "def silhouette_score(X, labels):\n",
        "  clusters = np.unique(labels)\n",
        "  samples = X.shape[0]\n",
        "\n",
        "  # Compute distances matrix\n",
        "  distances = np.zeros((samples, samples))\n",
        "  for i in range(samples):\n",
        "    for j in range(samples):\n",
        "      distances[i, j] = np.linalg.norm(X[i] - X[j])\n",
        "\n",
        "  # Compute scores\n",
        "  scores = np.zeros(samples)\n",
        "  for i in range(samples):\n",
        "    cluster = labels[i]\n",
        "    # Cohesion\n",
        "    same_samples = np.where(labels == cluster)[0]\n",
        "    same_samples = same_samples[same_samples != i]\n",
        "\n",
        "    if len(same_samples) == 0:\n",
        "      cohesion = 0\n",
        "    else:\n",
        "      cohesion = np.mean(distances[i, same_samples])\n",
        "\n",
        "    # Separation\n",
        "    separation = np.inf\n",
        "    for j in clusters:\n",
        "      if j != cluster:\n",
        "        separation_j = np.mean(distances[i, labels == j])\n",
        "        if separation_j < separation:\n",
        "          separation = separation_j\n",
        "\n",
        "    scores[i] = (separation - cohesion) / max(separation, cohesion)\n",
        "\n",
        "  return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Davies-Bouldin Index\n",
        "# Evaluates the quality of clustering reults.\n",
        "# Provides a numerical score based on two main factors: compactness and separation\n",
        "# Compactness measures how close data points are within a single cluster\n",
        "# Separation assesses the distance between different clusters\n",
        "\n",
        "# Begins by finding the centroid of each cluster. The intra-cluster distance is computed as the average distance\n",
        "# from each point to its centroid\n",
        "# Inter-cluster distance is measured between the centroids of pairs of clusters.\n",
        "# A lower index indicates better clustering with tight and well separated clusters. Begins from 0.\n",
        "# A higher index suggests potential overlaps/ineffective clustering.\n",
        "\n",
        "def davies_bouldin_index(X, labels):\n",
        "    clusters = np.unique(labels)\n",
        "    samples = X.shape[0]\n",
        "\n",
        "    centroids = []\n",
        "    dispersion = []\n",
        "\n",
        "    # Intra-Cluster\n",
        "    for cluster in clusters:\n",
        "        cluster_points = X[labels == cluster]\n",
        "        centroid = np.mean(cluster_points, axis=0)\n",
        "        centroids.append(centroid)\n",
        "        dispersion.append(np.mean(np.linalg.norm(cluster_points - centroid, axis=1)))\n",
        "\n",
        "    dispersion = np.array(dispersion)\n",
        "    centroids = np.array(centroids)\n",
        "\n",
        "    # Inter-Cluster\n",
        "    distances = np.linalg.norm(centroids[:, np.newaxis] - centroids[np.newaxis, :], axis=2)\n",
        "\n",
        "    max_ratios =[]\n",
        "    for i in range(len(clusters)):\n",
        "      current_index_ratio = []\n",
        "        for j in range(len(clusters)):\n",
        "          if i != j:\n",
        "            ratio = (dispersion[i]+dispersion[j]) / distances[i, j]\n",
        "            current_index_ratio.append(ratio)\n",
        "        max_ratios.append(np.max(current_index_ratio))\n",
        "\n",
        "    return np.mean(max_ratios)"
      ],
      "metadata": {
        "id": "NIxMrtsl2NyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calinski-Harabasz Index (CH Index)\n",
        "# Variance ratio criterion. Metric used to evaluate how well defined a cluster is.\n",
        "# The CH index looks at the data through the concept of variance. Measures the ratio of dispersion\n",
        "# within clusters.\n",
        "\n",
        "# Its identifying parameters are the Between-Cluster Variance and the Within-Cluster Variance.\n",
        "# Between-Cluster Variance:\n",
        "# How spread out the cluster centroids are from the global mean (of all data points). Should be high, indicating the clusters are far apart.\n",
        "# Within-Cluster Variance:\n",
        "# Measures how spread out the points are within each cluster relative to their own centroid. Should be low, indicating clusters are tight and compact.\n",
        "\n",
        "# CH = ((Between-Cluster Variance)/ (Within-Cluster Variance))*((N-k)/(k-1))\n",
        "\n",
        "# Can be any positive number. A higher index, is a better index (more dense a cluster is and well separated clusters are)\n",
        "# Function returns index and within_cluster_sum_of_squares\n",
        "def calinski_harabasz_index(X, labels):\n",
        "    clusters = np.unique(labels)\n",
        "    samples = X.shape[0]\n",
        "\n",
        "    mean_global = np.mean(X, axis=0)\n",
        "\n",
        "    # Between-Cluster Variance\n",
        "    between_cluster_sum_of_squares = 0\n",
        "    within_cluster_sum_of_squares = 0\n",
        "\n",
        "    for cluster in clusters:\n",
        "        cluster_points = X[labels == cluster]\n",
        "        mean_cluster = np.mean(cluster_points, axis=0)\n",
        "\n",
        "        nSamples = cluster_points.shape[0]\n",
        "        within_cluster_sum_of_squares += np.sum((cluster_points - mean_cluster)**2)\n",
        "        between_cluster_sum_of_squares += nSamples * np.sum((cluster_points - mean_global)**2)\n",
        "\n",
        "    index = ((between_cluster_sum_of_squares / (len(clusters) - 1))) / (within_cluster_sum_of_squares / (samples - len(clusters)))\n",
        "\n",
        "    return within_cluster_sum_of_squares, index\n",
        ""
      ],
      "metadata": {
        "id": "5EprTikj4s38"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusted Rand Index (ARI)\n",
        "# Measures the similarity between two sets of clustering results.\n",
        "# Measures the similarity between assignments. For example, if the ground truth for labels is [0,0,1] and the output of clustering is [1,1,0]\n",
        "# this would result in an ARI of 1, a perfect assignment score. To compute the ARI, we do the following:\n",
        "# TP: Points that are in the same cluster in the ground truth and the predictions\n",
        "# TN: Points that are in different clusters in both assignments\n",
        "# FP: Points are in the same cluster in prediction but different in ground truth\n",
        "# FN: Points are in different clusters in predictions but the same in ground truth\n",
        "\n",
        "# Rand Index = (TP+TN)/(TP+TN+FP+FN)\n",
        "\n",
        "def adjusted_rand_index(labels_true, labels_pred):\n",
        "  TP = 0\n",
        "  TN = 0\n",
        "  FP = 0\n",
        "  FN = 0\n",
        "\n",
        "  for i in range(0, len(labels_pred)-1):\n",
        "    for j in range(i+1, len(labels_pred)):\n",
        "      if labels_pred[i] == labels_pred[j]:\n",
        "        # Positive Pair\n",
        "        if labels_true[i] == labels_true[j]:\n",
        "          # True\n",
        "          TP += 1\n",
        "        else: #False\n",
        "          FP += 1\n",
        "      else: # Negative Pair\n",
        "        if labels_true[i] == labels_true[j]:\n",
        "          # False\n",
        "          FN += 1\n",
        "        else: # True\n",
        "          TN += 1\n",
        "\n",
        "  total_pairs = TP+TN+FP+FN\n",
        "\n",
        "  expected_index = ((TP+FP)*(TP+FN))/total_pairs\n",
        "  max_index = ((TP+FP)+(TP+FN))/2\n",
        "\n",
        "  # Prevent division by zero\n",
        "\n",
        "  if (max_index-expected_index) == 0:\n",
        "    return 0.0\n",
        "\n",
        "  ari = (TP-expected_index)/(max_index-expected_index)\n",
        "\n",
        "  return ari\n"
      ],
      "metadata": {
        "id": "lZubtLxz9o3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalized Mutual Information (NMI)\n",
        "# Provides a quantitative assessment of a clustering algorithm's ability to identify meaningful and\n",
        "# distinct groups within data\n",
        "# Given the knowledge of the ground truths class assignments (true labels) and the clustered\n",
        "# data output predicted labels, the NMI measures the agreement of the two assignments. Entropy is used.\n",
        "# Based on the concept of information theory introduced in decision trees. Aim to measure how much information\n",
        "# is shared between the ground truth labels and the predicted clusters.\n",
        "# Looks at the reduction of uncertainity in one variable given the knowledge of the other.\n",
        "\n",
        "# Ranges from [0,1], with one being a perfect correlation and 0 being no mutual information (i.e. clustering is indepent of true labels)\n",
        "\n",
        "\n",
        "def normalized_mutual_information(labels_true, labels_pred):\n",
        "  clusters = np.unique(labels_pred)\n",
        "  classes = np.unique(labels_true)\n",
        "\n",
        "  matrix = np.zeros((len(classes), len(clusters)))\n",
        "\n",
        "  for i, c in enumerate(classes):\n",
        "    for j, k in enumerate(clusters):\n",
        "      matrix[i, j] = np.sum((labels_true == c) & (labels_pred == k))\n",
        "\n",
        "  # Entropy calculation\n",
        "  pi_true = np.sum(matrix,axis=1)/len(labels_true)\n",
        "  pi_pred = np.sum(matrix,axis=0)/len(labels_pred)\n",
        "\n",
        "  pi_true = pi_true[pi_true > 0]\n",
        "  pi_pred = pi_pred[pi_pred > 0]\n",
        "\n",
        "  h_true = -np.sum(pi_true * np.log2(pi_true))\n",
        "  h_pred = -np.sum(pi_pred * np.log2(pi_pred))\n",
        "\n",
        "  mutual_information = 0\n",
        "\n",
        "  for i in range(len(classes)):\n",
        "    for j in range(len(clusters)):\n",
        "      if matrix[i, j] > 0:\n",
        "        # Probability of point being in class i and cluster j\n",
        "        p_ij = matrix[i, j] / len(labels_true)\n",
        "        # Probability of point being in class i\n",
        "        p_i  = np.sum(matrix[i, :]) / len(labels_true)\n",
        "        # Probability of point being in cluster j\n",
        "        p_j  = np.sum(matrix[:, j]) / len(labels_true)\n",
        "        mutual_information += p_ij * np.log2(p_ij / (p_i * p_j))\n",
        "\n",
        "  if (h_true + h_pred) == 0:\n",
        "    return 0.0\n",
        "\n",
        "  return 2* mutual_information / (h_true + h_pred)\n"
      ],
      "metadata": {
        "id": "buJYqtNaECP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Purity\n",
        "# Measures the extent to which a cluster has a single class\n",
        "# To measure it, we identify the most dominant class in a given cluster. Then count how many points in the cluster ACTUALLY belong to the dominant class, then normalize.\n",
        "# Ranges from [0,1] where 1 means perfect clustering and 0 is poor clustering.\n",
        "# It is not enough on its own as a model may tend to overfit (cluster for every point), thus it is paired with the aforementioned evaluation metrics.\n",
        "\n",
        "def purity(labels_true, labels_pred):\n",
        "  clusters = np.unique(labels_pred)\n",
        "  classes = np.unique(labels_true)\n",
        "\n",
        "  matrix = np.zeros(len(classes), len(clusters))\n",
        "\n",
        "  for i, c in enumerate(classes):\n",
        "    for j, k in enumerate(clusters):\n",
        "      matrix[i, j] = np.sum((labels_true == c) & (labels_pred == k))\n",
        "\n",
        "  dominant_class = np.max(matrix, axis=0)\n",
        "  return np.sum(dominant_class) / len(labels_true)\n"
      ],
      "metadata": {
        "id": "IVXXUbhHJAxz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}